


from pathlib import Path
import dill
import matplotlib.pyplot as plt
import missingno as msno
import numpy as np
import pandas as pd
import pendulum
import plotly.graph_objects as go
import plotly.express as px
import seaborn as sns
from imblearn.pipeline import Pipeline as imb_Pipeline
from loguru import logger
from sklearn import set_config
from sklearn.compose import make_column_transformer, ColumnTransformer
from sklearn.dummy import DummyClassifier
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (confusion_matrix,
                             classification_report,
                             ConfusionMatrixDisplay,
                             roc_auc_score,
                             accuracy_score,
                             precision_score,
                             recall_score,
                             f1_score,
                             RocCurveDisplay,
                             PrecisionRecallDisplay,
                            )
from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold
from sklearn.neighbors import KNeighborsClassifier
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, OrdinalEncoder, OneHotEncoder
from ucimlrepo import fetch_ucirepo, list_available_datasets
from yellowbrick.classifier import DiscriminationThreshold

set_config(display='diagram')
pd.set_option("display.max_columns", None)





HOME_DIR = Path("C:/Users/HP/Desktop/Livrables_groupe6/DATA")
DATA_TRAIN = HOME_DIR / "training.csv"
HOME_DIR.mkdir(parents=True, exist_ok=True)
print(f"Work directory: {HOME_DIR} \nData directory: {DATA_TRAIN}")


df = pd.read_csv(DATA_TRAIN, sep=";")
df.head()


df.tail()


df.shape


df.dtypes


df.info()


df.duplicated().sum()


df.isnull().sum()


df.describe(include = "all")





df['PricingStrategy'] = df['PricingStrategy'].astype('str')



df["FraudResult"].value_counts(normalize=False)


# Comptage des transactions frauduleuses et non frauduleuses
fraud_count = df[df["FraudResult"] == 1].shape[0]
non_fraud_count = df[df["FraudResult"] == 0].shape[0]

# Calcul des pourcentages
total = fraud_count + non_fraud_count
fraud_percentage = (fraud_count / total) * 100
non_fraud_percentage = (non_fraud_count / total) * 100

# Pr√©paration des donn√©es pour le graphique
labels = ['Fraud', 'Non-Fraud']
sizes = [fraud_percentage, non_fraud_percentage]
colors = ['orange', 'skyblue']

# Cr√©ation du graphique
fig, ax = plt.subplots(figsize=(8, 8))
ax.pie(sizes, labels=labels, autopct='%1.2f%%', startangle=90, colors=colors)

# Cercle central pour un effet "donut"
centre_circle = plt.Circle((0, 0), 0.70, fc='white')
fig.gca().add_artist(centre_circle)

# Titre du graphique
plt.title('Percentage of Fraud and Non-Fraud Transactions')
plt.show()



categorical_columns = df.select_dtypes(include="object").columns
categorical_columns


for col_name in categorical_columns:
    logger.info(f"{col_name} ==============\n {df[col_name].value_counts(dropna=False)}\n")


# Cr√©ation des variables d√©riv√©es de AccountId, SubscriptionId, CustomerId
df['CustomerId_abs_amount_sum'] = df.groupby('CustomerId')['Amount'].transform(lambda x: x.abs().sum())
df['SubscriptionId_transaction_count'] = df.groupby('SubscriptionId')['TransactionId'].transform('count')
df['CustomerId_abs_amount_std'] = df.groupby('CustomerId')['Amount'].transform(lambda x: x.abs().std())
df['CustomerId_abs_amount_std'] = df['CustomerId_abs_amount_std'].fillna(0)


# Cr√©ation des variables d√©riv√©es de TransactionStartTime
# Variable transaction_type (cr√©dit ou d√©bit)
df['TransactionType'] = df['Amount'].apply(lambda x: 'Credit' if x < 0 else 'Debit').astype('object')

# Conversion de la variable temporelle
df['TransactionStartTime'] = pd.to_datetime(df['TransactionStartTime'])

# Extraction des informations utiles
df['TransactionHour'] = df['TransactionStartTime'].dt.hour
df['TransactionDay'] = df['TransactionStartTime'].dt.day_name(locale='fr_FR')

# Cr√©ation de la variable MomentOfDay
def get_moment(hour):
    if 6 <= hour < 13:
        return 'matin'
    elif 13 <= hour <= 20:
        return 'apres-midi'
    else:
        return 'nuit'

df['MomentOfDay'] = df['TransactionHour'].apply(get_moment)




# V√©rifie si chaque ProductId correspond √† une seule ProductCategory
mapping_check = df.groupby("ProductId")["ProductCategory"].nunique()
print("Nombre de ProductId ayant plus d'une cat√©gorie :", (mapping_check > 1).sum())



# Certaines colonnes n‚Äôapportent pas d'information utile au mod√®le
cols_to_drop = ['TransactionId', 'BatchId', 'CustomerId','AccountId', 'SubscriptionId', 
                'CountryCode', 'CurrencyCode','TransactionStartTime','TransactionHour','ProductCategory']
df.drop(columns=cols_to_drop, inplace=True)





categorical_columns = df.select_dtypes(include="object").columns
categorical_columns


for col in categorical_columns:
    unique_col = df[col].unique();
    col_counts = df[col].value_counts()
    plt.figure(figsize=(16, 9))
    plt.xlabel(unique_col)
    plt.ylabel(col_counts)
    bars = col_counts.plot(kind='bar', color='skyblue')
    for bar in bars.patches:
        yval = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2, yval + 20000, f'{yval:,.0f}', ha='center', va='bottom', fontsize=10, color='black')
    plt.show()


# Recoder la variable ProduitId 
# Calculer la fr√©quence des produits
frequencies_product = df['ProductId'].value_counts(normalize=True) * 100

# S√©lectionner les produits dont la fr√©quence d√©passe 12%
products_above_12 = frequencies_product[frequencies_product > 12]
products_list = products_above_12.index.tolist()
def recode_product(X):
  try:
        if 'ProductId' in X.columns:
            X = X.copy()
            X['ProductId'] = X['ProductId'].apply(lambda x: x if x in products_list else 'Other')
        return X
  except:
        print("V√©rifier la liste des colonnes")

df = recode_product(df)

df['ProductId'].value_counts().plot(kind='pie',autopct='%1.1f%%')
plt.title('ProductId')
plt.axis('equal')
plt.show()



# Recoder la variable providerID 
frequencies_provider = df['ProviderId'].value_counts(normalize=True) * 100

# S√©lectionner les provider dont la fr√©quence d√©passe 12%
provider_above_12 = frequencies_provider[frequencies_provider > 12]

provider_list = provider_above_12.index.tolist()

def recode_provider(X):
  try:
        if 'ProviderId' in X.columns:
            X = X.copy()
            X['ProviderId'] = X['ProviderId'].apply(lambda x: x if x in provider_list else 'Other')
        return X
  except:
        print("V√©rifier la liste des colonnes")

df = recode_provider(df)

df['ProviderId'].value_counts().plot(kind='pie',autopct='%1.1f%%')
plt.title('ProviderId')
plt.axis('equal')
plt.show()



# Recoder la variable ChannelId

channel_list = ['ChannelId_2','ChannelId_3']
def recode_channel(X):
  try:
        if 'ChannelId' in X.columns:
            X = X.copy()
            X['ChannelId'] = X['ChannelId'].apply(lambda x: x if x in channel_list else 'Other')
        return X
  except:
        print("V√©rifier la liste des colonnes")

df = recode_channel(df)

# Visualiser
df['ChannelId'].value_counts().plot(kind='pie',autopct='%1.1f%%')
plt.title('ChannelId')
plt.axis('equal')
plt.show()



# Recoder la variable PricingStrategy
Pricing_list = ["2","4"]

def recode_pricing(X):
  try:
        if 'PricingStrategy' in X.columns:
            X = X.copy()
            X['PricingStrategy'] = X['PricingStrategy'].apply(lambda x: x if x in Pricing_list else 'Other')
        return X
  except:
        print("V√©rifier la liste des colonnes")

df = recode_pricing(df)

# Visualiser
df['PricingStrategy'].value_counts().plot(kind='pie',autopct='%1.1f%%')
plt.title('PricingStrategy')
plt.axis('equal')
plt.show()






numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns
numeric_columns = [col for col in numeric_columns if col != 'FraudResult']
numeric_columns


# Initialize a figure
fig = go.Figure()

# Iterate over numeric columns in the DataFrame
for column in numeric_columns:
    fig.add_trace(go.Box(
        y=df[column],
        name=column,
        marker=dict(color='skyblue')
    ))

# Update layout with a title and axis labels
fig.update_layout(
    title='Distribution of Numeric Columns',
    yaxis_title='Values',
    xaxis_title='Numeric Columns'
)

# Show the figure
fig.show()



import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Cr√©er les colonnes log si elles n'existent pas
df['log_Value'] = np.log1p(df['Value'])  # log1p pour √©viter log(0)
df['log_abs_Amount'] = np.log1p(df['Amount'].abs())
df['log_CustomerId_abs_amount_sum'] = np.log1p(df['CustomerId_abs_amount_sum'])

# Cr√©er la figure
fig, axes = plt.subplots(1, 6, figsize=(18, 6))

# Tracer les bo√Ætes
sns.boxplot(y=df['Value'], ax=axes[0], color='skyblue')
axes[0].set_title("Value")

sns.boxplot(y=df['log_Value'], ax=axes[1], color='lightgreen')
axes[1].set_title("log(Value)")

sns.boxplot(y=df['Amount'], ax=axes[2], color='salmon')
axes[2].set_title("Amount")

sns.boxplot(y=df['log_abs_Amount'], ax=axes[3], color='violet')
axes[3].set_title("log(|Amount|)")

sns.boxplot(y=df['CustomerId_abs_amount_sum'], ax=axes[4], color='skyblue')
axes[4].set_title("CustomerId_abs_amount_sum")
                                               
sns.boxplot(y=df['log_CustomerId_abs_amount_sum'], ax=axes[5], color='salmon')
axes[5].set_title("log_CustomerId_abs_amount_sum")

                                               
plt.tight_layout()
plt.show()


import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Cr√©er la figure avec 4 subplots en ligne
fig, axes = plt.subplots(1, 6, figsize=(20, 5))

# Tracer chaque distribution
sns.histplot(df['Value'], kde=True, color='lightgreen', ax=axes[0])
axes[0].set_title("Value")
axes[0].set_ylim(0, 590) 

sns.histplot(df['log_Value'], kde=True, color='lightgreen', ax=axes[1])
axes[1].set_title("log(Value)")

sns.histplot(df['Amount'], kde=True, color='violet', ax=axes[2])
axes[2].set_title("Amount")
axes[2].set_ylim(0, 150)  

sns.histplot(df['log_abs_Amount'], kde=True, color='violet', ax=axes[3])
axes[3].set_title("log(|Amount|)")

sns.histplot(df['CustomerId_abs_amount_sum'], kde=True, color='salmon', ax=axes[4])
axes[4].set_title("CustomerId_abs_amount_sum")

sns.histplot(df['log_CustomerId_abs_amount_sum'], kde=True, color='salmon', ax=axes[5])
axes[5].set_title("log_CustomerId_abs_amount_sum")

plt.tight_layout()
plt.show()






from scipy.stats import chi2_contingency
import numpy as np
import pandas as pd

var_names = []
chi2_scores = []
p_values = []
cramer_vs = []

for var in categorical_columns:
    contingency_table = pd.crosstab(df['FraudResult'], df[var])
    chi2, p, dof, expected = chi2_contingency(contingency_table)

    # Calcul du nombre total d'observations
    n = contingency_table.values.sum()
    k, r = contingency_table.shape

    # Calcul corrig√© du V de Cram√©r
    cramer_v = np.sqrt(chi2 / (n * (min(k - 1, r - 1))))

    # Stockage des r√©sultats
    var_names.append(var)
    chi2_scores.append(chi2)
    p_values.append(p)
    cramer_vs.append(cramer_v)

# R√©sultat final sous forme de DataFrame
resultats = pd.DataFrame({
    'Variable': var_names,
    'Chi2': chi2_scores,
    'P-value': p_values,
    'Cramer V': cramer_vs
})

# Affichage des r√©sultats
print(resultats.sort_values(by='Cramer V', ascending=False))




fraud_transactions = df[df["FraudResult"] == 1]
for col in categorical_columns:
    fraud_counts_by_columns = fraud_transactions.groupby(col).size()
    plt.figure(figsize=(8, 8))
    plt.pie(fraud_counts_by_columns, labels=fraud_counts_by_columns.index , autopct='%1.1f%%', startangle=90)
    plt.title(f'Proportion of Fraud Transactions by {col}')
    plt.show()



for col_name in categorical_columns:
    feature_FraudResult_counts = df.groupby([col_name, 'FraudResult']).size().unstack()
    
    fig = px.bar(feature_FraudResult_counts,
                 barmode='stack',  # Stack bars for income categories
                 title=f'Relationship between FraudResult and {col_name}',
                 labels={'value': 'Count'}
                )
    fig.show()





# Cr√©ation de la colonne "Ecart" entre Amount et Value
df['Amount_Value_Ecart'] = df['Value'] - df['Amount'].abs()

poids_non_fraud = (95469 + 193) / 95469  # Poids pour la classe non frauduleuse
poids_fraud = (95469 + 193) / 193        # Poids pour la classe frauduleuse

# Ajout des poids dans le DataFrame
df['Weight'] = df['FraudResult'].apply(lambda x: poids_fraud if x == 1 else poids_non_fraud)

# S√©paration des donn√©es par classe FraudResult
fraud_df = df[df['FraudResult'] == 1]
non_fraud_df = df[df['FraudResult'] == 0]

# Calcul des statistiques descriptives de l'√©cart avec pond√©ration
fraud_weighted = fraud_df[['Amount_Value_Ecart', 'Weight']].apply(lambda x: x['Amount_Value_Ecart'] * x['Weight'], axis=1).sum() / fraud_df['Weight'].sum()
non_fraud_weighted = non_fraud_df[['Amount_Value_Ecart', 'Weight']].apply(lambda x: x['Amount_Value_Ecart'] * x['Weight'], axis=1).sum() / non_fraud_df['Weight'].sum()

# Affichage des r√©sultats
print(f"√âcart moyen pond√©r√© (Frauduleuses) : {fraud_weighted}")
print(f"√âcart moyen pond√©r√© (Non Frauduleuses) : {non_fraud_weighted}")

# Comparaison graphique avec pond√©ration
plt.figure(figsize=(12, 6))
sns.kdeplot(fraud_df['Amount_Value_Ecart'], label='Frauduleuses')
sns.kdeplot(non_fraud_df['Amount_Value_Ecart'], label='Non frauduleuses')
plt.title("Comparaison de l'√©cart pond√©r√© entre Amount et Value (Frauduleuses vs Non frauduleuses)")
plt.xlabel("Ecart (|Amount - Value|)")
plt.ylabel("Densit√©")
plt.legend()
plt.show()
# conclusion : L'√©cart entre Amount et Value semble √™tre un bon indicateur pour distinguer les transactions frauduleuses des transactions non frauduleuses
df.drop(columns="Weight", inplace=True)


numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns
numeric_columns = [col for col in numeric_columns if col != 'FraudResult']
numeric_columns


from scipy import stats

var_names = []
f_stat_values_fraud = []
p_values_fraud = []
f_stat_values_non_fraud = []
p_values_non_fraud = []

for var in numeric_columns:
    # Groupes pour les transactions non frauduleuses et frauduleuses
    group1 = df[df['FraudResult'] == 0][var]  # Non-fraudulent transactions
    group2 = df[df['FraudResult'] == 1][var]  # Fraudulent transactions

    # Test ANOVA pour comparer les deux groupes (fraude et non fraude)
    f_stat, p = stats.f_oneway(group1, group2)

    # Ajouter les r√©sultats pour chaque variable
    var_names.append(var)
    f_stat_values_fraud.append(f_stat)
    p_values_fraud.append(p)
    f_stat_values_non_fraud.append(f_stat)  # M√™me F-statistique pour les deux groupes
    p_values_non_fraud.append(p)           # M√™me p-value pour les deux groupes

# Cr√©ation d'un DataFrame avec les r√©sultats
resultats = pd.DataFrame({
    'Variable': var_names,
    'F-Statistic (Fraud vs Non-Fraud)': f_stat_values_fraud,
    'P-value (Fraud vs Non-Fraud)': p_values_fraud
})

resultats



import scipy.stats as stats
import pandas as pd

var_names = []
ks_stat_nonfraud = []
p_values_nonfraud = []
ks_stat_fraud = []
p_values_fraud = []

for var in numeric_columns:
    # Groupe non frauduleux
    group_nonfraud = df[df['FraudResult'] == 0][var]
    group_nonfraud_std = (group_nonfraud - group_nonfraud.mean()) / group_nonfraud.std()
    ks_nonfraud = stats.kstest(group_nonfraud_std, 'norm')
    
    # Groupe frauduleux
    group_fraud = df[df['FraudResult'] == 1][var]
    group_fraud_std = (group_fraud - group_fraud.mean()) / group_fraud.std()
    ks_fraud = stats.kstest(group_fraud_std, 'norm')
    
    # Stocker les r√©sultats
    var_names.append(var)
    ks_stat_nonfraud.append(ks_nonfraud.statistic)
    p_values_nonfraud.append(ks_nonfraud.pvalue)
    ks_stat_fraud.append(ks_fraud.statistic)
    p_values_fraud.append(ks_fraud.pvalue)

# Cr√©er le DataFrame des r√©sultats
resultats = pd.DataFrame({
    'Variable': var_names,
    'KS Stat (Non Fraude)': ks_stat_nonfraud,
    'P-value (Non Fraude)': p_values_nonfraud,
    'KS Stat (Fraude)': ks_stat_fraud,
    'P-value (Fraude)': p_values_fraud
})

resultats



# Certaines colonnes n‚Äôapportent plus d'information utile au mod√®le
cols_to_drop = ['Amount', 'log_Value', 'log_abs_Amount','CustomerId_abs_amount_sum']
df.drop(columns=cols_to_drop, inplace=True)


numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns
numeric_columns = [col for col in numeric_columns if col != 'FraudResult']
numeric_columns



import seaborn as sns
import matplotlib.pyplot as plt


# Cr√©er une figure pour afficher les graphiques
plt.figure(figsize=(12, 6))

# Boucle sur les variables √† visualiser
for i, var in enumerate(numeric_columns):
    plt.subplot(3, 2, i + 1)
    
    # Tracer les histogrammes et les courbes de densit√©
    sns.histplot(data=df, x=var, hue="FraudResult", kde=True, stat="density", common_norm=False, bins=30)
    
    # Ajouter des labels et un titre
    plt.title(f'Distribution de {var} par type de transaction')
    plt.xlabel(var)
    plt.ylabel('Density')
    
plt.tight_layout()
plt.show()




for column in numeric_columns:
    fig = px.box(
        data_frame=df,
        x='FraudResult',  
        y=column,
        title=f"Distribution de {column} par FraudResult",
        labels={'FraudResult': 'R√©sultat', column: column}
    )
    fig.show()



# Combiner 'numeric_columns' et 'FraudResult' dans une seule liste
columns_to_select = numeric_columns + ['FraudResult']

# Utiliser la liste r√©sultante pour s√©lectionner les colonnes et g√©n√©rer le pairplot
sns.pairplot(df[columns_to_select], hue="FraudResult", corner=False)






correlation = df[numeric_columns].corr(method="pearson")


# correlation plot
plt.figure(figsize=(10, 7))
corr = df[numeric_columns].corr(method="pearson")
mask = np.zeros_like(corr)
mask[np.triu_indices_from(mask)] = True

sns.heatmap(corr, cmap='Greens', annot=True, square=True,
            fmt='.3f',
            mask=mask,
            cbar=True, vmin=-1, vmax=1);











from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from imblearn.pipeline import Pipeline as ImbPipeline
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import pandas as pd

# ----------------------------
# 1. S√©paration des variables
# ----------------------------
X = df.drop('FraudResult', axis=1)
y = df['FraudResult']

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)

# ----------------------------
# 2. Pr√©traitement
# ----------------------------
preprocessor = ColumnTransformer(transformers=[
    ('num', StandardScaler(), numeric_columns),
    ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_columns)
])

# ----------------------------
# 0. Baseline (mod√®le par d√©faut)
# ----------------------------
print("üìå Baseline : R√©gression Logistique sans tuning ni sampling")

baseline_pipeline = ImbPipeline([
    ('preproc', preprocessor),
    ('clf', LogisticRegression(random_state=42))
])

baseline_pipeline.fit(X_train, y_train)
y_pred_baseline = baseline_pipeline.predict(X_val)
y_proba_baseline = baseline_pipeline.predict_proba(X_val)[:, 1]

print("‚û°Ô∏è Performance du mod√®le baseline :")
print(f"Accuracy  : {accuracy_score(y_val, y_pred_baseline):.4f}")
print(f"Pr√©cision : {precision_score(y_val, y_pred_baseline, zero_division=0):.4f}")
print(f"Rappel    : {recall_score(y_val, y_pred_baseline):.4f}")
print(f"F1-score  : {f1_score(y_val, y_pred_baseline):.4f}")
print(f"ROC AUC   : {roc_auc_score(y_val, y_proba_baseline):.4f}")
# ----------------------------
# Affichage des hyperparam√®tres par d√©faut
# ----------------------------
print("\nüìã Hyperparam√®tres par d√©faut de la R√©gression Logistique :")
for param, val in baseline_pipeline.named_steps['clf'].get_params().items():
    print(f"{param}: {val}")






from sklearn.model_selection import GridSearchCV, StratifiedKFold
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from imblearn.pipeline import Pipeline as ImbPipeline
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import pandas as pd

# ----------------------------
# 1. S√©paration des variables
# ----------------------------
X = df.drop('FraudResult', axis=1)
y = df['FraudResult']

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)

# ----------------------------
# 2. Pr√©traitement dans un transformer unique
# ----------------------------
preprocessor = ColumnTransformer(transformers=[
    ('num', StandardScaler(), numeric_columns),
    ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_columns)
])

# ----------------------------
# 3. Param√®tres de recherche pour RandomForest et sampling
# ----------------------------
# Param√®tres de base du classifieur
param_grid = {
    'clf__penalty': ['l2'],
    'clf__C': [0.1, 10],
    'clf__solver': ['lbfgs'],
    'clf__max_iter': [6000]
}

# Param√®tres avec sur√©chantillonnage SMOTE
param_grid_smote = param_grid.copy()
param_grid_smote.update({
    'smote__sampling_strategy': [0.25, 0.5]
})

# Param√®tres avec sous-√©chantillonnage
param_grid_under = param_grid.copy()
param_grid_under.update({
    'under__sampling_strategy': [0.25, 0.5]
})

# ----------------------------
# 4. Pipelines avec diff√©rentes m√©thodes
# ----------------------------
pipelines = {
    "Original": ImbPipeline([
        ('preproc', preprocessor),
        ('clf', LogisticRegression())
    ]),
    "SMOTE": ImbPipeline([
        ('preproc', preprocessor),
        ('smote', SMOTE(random_state=42)),
        ('clf', LogisticRegression())
    ]),
    "UnderSampling": ImbPipeline([
        ('preproc', preprocessor),
        ('under', RandomUnderSampler(random_state=42)),
        ('clf', LogisticRegression())
    ]),
    "Pond√©ration": ImbPipeline([
        ('preproc', preprocessor),
        ('clf', LogisticRegression(class_weight='balanced'))
    ])
}

# ----------------------------
# 5. Entra√Ænement et √©valuation
# ----------------------------
resultats = []


for methode, pipeline in pipelines.items():
    print(f"\nüîç M√©thode : {methode}")

    if "SMOTE" in methode:
        tuned_parameters = param_grid_smote
    elif "UnderSampling" in methode:
        tuned_parameters = param_grid_under
    else:
        tuned_parameters = param_grid
    
    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)    
    grid = GridSearchCV(pipeline, tuned_parameters, cv=cv, scoring='f1', n_jobs=-1, error_score='raise')
    grid.fit(X_train, y_train)

    
    best_model = grid.best_estimator_
    y_pred = best_model.predict(X_val)
    y_proba = best_model.predict_proba(X_val)[:, 1]

    resultats.append({
        'M√©thode': methode,
        'Accuracy': accuracy_score(y_val, y_pred),
        'Pr√©cision': precision_score(y_val, y_pred, zero_division=0),
        'Rappel': recall_score(y_val, y_pred),
        'F1-score': f1_score(y_val, y_pred),
        'ROC AUC': roc_auc_score(y_val, y_proba),
        'Best Params': grid.best_params_
    })

# ----------------------------
# 6. R√©sum√© des r√©sultats
# ----------------------------
df_resultats = pd.DataFrame(resultats)
df_resultats = df_resultats.sort_values(by='F1-score', ascending=False).reset_index(drop=True)

print("\nüìä R√©sum√© des performances pour regression logistique:")
print(df_resultats)






# Recr√©er le pipeline avec les meilleurs param√®tres
from sklearn.linear_model import LogisticRegression
from imblearn.pipeline import Pipeline as ImbPipeline
from imblearn.under_sampling import RandomUnderSampler

# Meilleurs hyperparam√®tres
best_params = df_resultats[df_resultats['M√©thode'] == 'UnderSampling']['Best Params'].values[0]
# Reconstruire le pipeline final
best_pipeline_regressin_logistique = ImbPipeline([
    ('preproc', preprocessor),
    ('under', RandomUnderSampler(sampling_strategy=best_params['under__sampling_strategy'], random_state=42)),
    ('clf', LogisticRegression(
        penalty=best_params['clf__penalty'],
        C=best_params['clf__C'],
        solver=best_params['clf__solver'],
        max_iter=best_params['clf__max_iter']
    ))
])


# Entra√Æner le pipeline final
print("best hyperam", best_params)
best_pipeline_regressin_logistique.fit(X_train, y_train)



from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt

# 1. Pr√©dictions du mod√®le
y_pred = best_pipeline_regressin_logistique.predict(X_val)

# 2. Matrice de confusion normalis√©e par ligne (pourcentage par classe r√©elle)
conf_matrix_normalized = confusion_matrix(y_val, y_pred, normalize='true') * 100  # en %

# 3. Affichage de la matrice de confusion normalis√©e
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix_normalized, annot=True, fmt='.3f', cmap='Blues',
            xticklabels=['Classe 0', 'Classe 1'],
            yticklabels=['Classe 0', 'Classe 1'])
plt.title('Matrice de Confusion Normalis√©e (par ligne, en %)')
plt.xlabel('Pr√©diction')
plt.ylabel('V√©rit√© terrain')
plt.show()

# 4. Affichage du rapport de classification
print("Rapport de classification :\n", classification_report(y_val, y_pred))



import dill

# Enregistrer le meilleur mod√®le avec dill
with open('best_Regression_logistique.dill', 'wb') as f:
    dill.dump(best_pipeline_regressin_logistique, f)
    
# Charger le mod√®le avec dill
with open('best_Regression_logistique.dill', 'rb') as f:
    loaded_model = dill.load(f)
# Effectuer une pr√©diction pour tester le mod√®le charg√©
y_pred = loaded_model.predict(X_val)
print(y_pred)









from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from imblearn.pipeline import Pipeline as ImbPipeline
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import pandas as pd

# ----------------------------
# 1. S√©paration des variables
# ----------------------------
X = df.drop('FraudResult', axis=1)
y = df['FraudResult']

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)

# ----------------------------
# 2. Pr√©traitement
# ----------------------------
preprocessor = ColumnTransformer(transformers=[
    ('num', StandardScaler(), numeric_columns),
    ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_columns)
])

# ----------------------------
# 0. Baseline (mod√®le par d√©faut)
# ----------------------------
print("üìå Baseline : K-Nearest Neighbors sans tuning ni sampling")

baseline_pipeline = ImbPipeline([
    ('preproc', preprocessor),
    ('clf', KNeighborsClassifier())
])

baseline_pipeline.fit(X_train, y_train)
y_pred_baseline = baseline_pipeline.predict(X_val)
y_proba_baseline = baseline_pipeline.predict_proba(X_val)[:, 1]

print("‚û°Ô∏è Performance du mod√®le baseline :")
print(f"Accuracy  : {accuracy_score(y_val, y_pred_baseline):.4f}")
print(f"Pr√©cision : {precision_score(y_val, y_pred_baseline, zero_division=0):.4f}")
print(f"Rappel    : {recall_score(y_val, y_pred_baseline):.4f}")
print(f"F1-score  : {f1_score(y_val, y_pred_baseline):.4f}")
print(f"ROC AUC   : {roc_auc_score(y_val, y_proba_baseline):.4f}")

# ----------------------------
# Affichage des hyperparam√®tres par d√©faut
# ----------------------------
print("\nüìã Hyperparam√®tres par d√©faut de K-Nearest Neighbors :")
for param, val in baseline_pipeline.named_steps['clf'].get_params().items():
    print(f"{param}: {val}")






from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from imblearn.pipeline import Pipeline as ImbPipeline
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import pandas as pd

# ----------------------------
# 1. S√©paration des variables
# ----------------------------
X = df.drop('FraudResult', axis=1)
y = df['FraudResult']

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)

# ----------------------------
# 2. Pr√©traitement dans un transformer unique
# ----------------------------
preprocessor = ColumnTransformer(transformers=[
    ('num', StandardScaler(), numeric_columns),
    ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_columns)
])

# ----------------------------
# 3. Param√®tres de recherche pour KNN et sampling
# ----------------------------
# Param√®tres de base du classifieur KNN
param_grid = {
    'clf__n_neighbors': [3, 10],
    'clf__metric': ['minkowski', 'euclidean'],
    'clf__weights': ['uniform', 'distance'],
}

# Param√®tres avec sur√©chantillonnage SMOTE
param_grid_smote = param_grid.copy()
param_grid_smote.update({
    'smote__sampling_strategy': [0.25, 0.5]
})

# Param√®tres avec sous-√©chantillonnage
param_grid_under = param_grid.copy()
param_grid_under.update({
    'under__sampling_strategy': [0.25, 0.5]
})

# ----------------------------
# 4. Pipelines avec diff√©rentes m√©thodes
# ----------------------------
pipelines = {
    "Original": ImbPipeline([
        ('preproc', preprocessor),
        ('clf', KNeighborsClassifier())
    ]),
    "SMOTE": ImbPipeline([
        ('preproc', preprocessor),
        ('smote', SMOTE(random_state=42)),
        ('clf', KNeighborsClassifier())
    ]),
    "UnderSampling": ImbPipeline([
        ('preproc', preprocessor),
        ('under', RandomUnderSampler(random_state=42)),
        ('clf', KNeighborsClassifier())
    ]),
    "Pond√©ration": ImbPipeline([
        ('preproc', preprocessor),
        ('clf', KNeighborsClassifier(weights='uniform'))  # "uniform" pour l'√©quilibre des poids
    ])
}

# ----------------------------
# 5. Entra√Ænement et √©valuation
# ----------------------------
resultats_knn = []

for methode, pipeline in pipelines.items():
    print(f"\nüîç M√©thode : {methode}")

    if "SMOTE" in methode:
        tuned_parameters = param_grid_smote
    elif "UnderSampling" in methode:
        tuned_parameters = param_grid_under
    else:
        tuned_parameters = param_grid
    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)    
    grid = GridSearchCV(pipeline, tuned_parameters, cv=cv, scoring='f1', n_jobs=-1, error_score='raise')
    grid.fit(X_train, y_train)
    best_model = grid.best_estimator_
    y_pred = best_model.predict(X_val)
    y_proba = best_model.predict_proba(X_val)[:, 1]

    resultats_knn.append({
        'M√©thode': methode,
        'Accuracy': accuracy_score(y_val, y_pred),
        'Pr√©cision': precision_score(y_val, y_pred, zero_division=0),
        'Rappel': recall_score(y_val, y_pred),
        'F1-score': f1_score(y_val, y_pred),
        'ROC AUC': roc_auc_score(y_val, y_proba),
        'Best Params': grid.best_params_
    })

# ----------------------------
# 6. R√©sum√© des r√©sultats
# ----------------------------
df_resultats_knn = pd.DataFrame(resultats_knn)
df_resultats_knn = df_resultats_knn.sort_values(by='F1-score', ascending=False).reset_index(drop=True)

print("\nüìä R√©sum√© des performances pour K-Nearest Neighbors :")
print(df_resultats_knn)






from imblearn.pipeline import Pipeline as ImbPipeline
from imblearn.over_sampling import SMOTE
from sklearn.neighbors import KNeighborsClassifier

# Meilleurs hyperparam√®tres obtenus par SMOTE
best_params = df_resultats_knn[df_resultats_knn['M√©thode'] == 'SMOTE']['Best Params'].values[0]
# Reconstruire le pipeline final avec SMOTE et KNN
best_pipeline_KNN= ImbPipeline([
    ('preproc', preprocessor),
    ('smote', SMOTE(sampling_strategy=best_params['smote__sampling_strategy'], random_state=42)),
    ('clf', KNeighborsClassifier(
        n_neighbors=best_params['clf__n_neighbors'],
        weights=best_params['clf__weights']

    ))
])
print("best hyperparam", best_params)
# Entra√Æner le pipeline final
best_pipeline_KNN.fit(X_train, y_train)



from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# 1. Pr√©dictions du mod√®le
y_pred = best_pipeline_KNN.predict(X_val)

# 2. Matrice de confusion normalis√©e par ligne (pourcentage par classe r√©elle)
conf_matrix_normalized = confusion_matrix(y_val, y_pred, normalize='true') * 100  # en %

# 3. Affichage de la matrice de confusion en pourcentage (ligne)
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix_normalized, annot=True, fmt='.3f', cmap='Blues',
            xticklabels=['Classe 0', 'Classe 1'],
            yticklabels=['Classe 0', 'Classe 1'])
plt.title('Matrice de Confusion Normalis√©e (par ligne, en %)')
plt.xlabel('Pr√©diction')
plt.ylabel('V√©rit√© terrain')
plt.show()

# 4. Rapport de classification
print("Rapport de classification :\n", classification_report(y_val, y_pred))




import dill

# Enregistrer le meilleur mod√®le avec dill
with open('best_KNN.dill', 'wb') as f:
    dill.dump(best_pipeline_KNN, f)
    
# Charger le mod√®le avec dill
with open('best_KNN.dill', 'rb') as f:
    loaded_model = dill.load(f)
# Effectuer une pr√©diction pour tester le mod√®le charg√©
y_pred = loaded_model.predict(X_val)
print(y_pred)









from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from imblearn.pipeline import Pipeline as ImbPipeline
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import pandas as pd

# ----------------------------
# 1. S√©paration des variables
# ----------------------------
X = df.drop('FraudResult', axis=1)
y = df['FraudResult']

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)

# ----------------------------
# 2. Pr√©traitement
# ----------------------------
preprocessor = ColumnTransformer(transformers=[
    ('num', StandardScaler(), numeric_columns),
    ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_columns)
])

# ----------------------------
# 0. Baseline (mod√®le par d√©faut)
# ----------------------------
print("üìå Baseline : Decision Tree sans tuning ni sampling")

baseline_pipeline = ImbPipeline([
    ('preproc', preprocessor),
    ('clf', DecisionTreeClassifier(random_state=42))
])

baseline_pipeline.fit(X_train, y_train)
y_pred_baseline = baseline_pipeline.predict(X_val)
y_proba_baseline = baseline_pipeline.predict_proba(X_val)[:, 1]

print("‚û°Ô∏è Performance du mod√®le baseline :")
print(f"Accuracy  : {accuracy_score(y_val, y_pred_baseline):.4f}")
print(f"Pr√©cision : {precision_score(y_val, y_pred_baseline, zero_division=0):.4f}")
print(f"Rappel    : {recall_score(y_val, y_pred_baseline):.4f}")
print(f"F1-score  : {f1_score(y_val, y_pred_baseline):.4f}")
print(f"ROC AUC   : {roc_auc_score(y_val, y_proba_baseline):.4f}")

# ----------------------------
# Affichage des hyperparam√®tres par d√©faut
# ----------------------------
print("\nüìã Hyperparam√®tres par d√©faut de Decision Tree :")
for param, val in baseline_pipeline.named_steps['clf'].get_params().items():
    print(f"{param}: {val}")






from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from imblearn.pipeline import Pipeline as ImbPipeline
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import pandas as pd

# ----------------------------
# 1. S√©paration des variables
# ----------------------------
X = df.drop('FraudResult', axis=1)
y = df['FraudResult']

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)

# ----------------------------
# 2. Pr√©traitement dans un transformer unique
# ----------------------------
preprocessor = ColumnTransformer(transformers=[
    ('num', StandardScaler(), numeric_columns),
    ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_columns)
])

# ----------------------------
# 3. Param√®tres de recherche pour Decision Tree
# ----------------------------
param_grid = {
    'clf__criterion': ['gini', 'entropy'],  # Crit√®re de d√©cision
    'clf__max_depth': [5, 10],  # Profondeur maximale de l'arbre
    'clf__min_samples_split': [4, 8],  # Nombre minimal d'√©chantillons pour diviser un noeud
    'clf__min_samples_leaf': [3, 7],  # Nombre minimal d'√©chantillons dans une feuille
    'clf__max_features': [None, 'sqrt'],  # Nombre maximal de caract√©ristiques √† consid√©rer
    'clf__random_state': [42]  # Fixation de l'al√©a pour reproductibilit√©
}

# Param√®tres avec sur√©chantillonnage SMOTE
param_grid_smote = param_grid.copy()
param_grid_smote.update({
    'smote__sampling_strategy': [0.25, 0.5]
})

# Param√®tres avec sous-√©chantillonnage
param_grid_under = param_grid.copy()
param_grid_under.update({
    'under__sampling_strategy': [0.25, 0.5]
})


# ----------------------------
# 4. D√©finition des pipelines imbriqu√©s
# ----------------------------
pipelines = {
    "Original": ImbPipeline([
        ('preproc', preprocessor),
        ('clf', DecisionTreeClassifier(random_state=42))
    ]),
    "SMOTE": ImbPipeline([
        ('preproc', preprocessor),
        ('smote', SMOTE(random_state=42)),
        ('clf', DecisionTreeClassifier(random_state=42))
    ]),
    "UnderSampling": ImbPipeline([
        ('preproc', preprocessor),
        ('under', RandomUnderSampler(random_state=42)),
        ('clf', DecisionTreeClassifier(random_state=42))
    ]),
    "Pond√©ration": ImbPipeline([
        ('preproc', preprocessor),
        ('clf', DecisionTreeClassifier(random_state=42, class_weight='balanced'))  # Pond√©ration des classes
    ])
}

# ----------------------------
# 5. Boucle d‚Äôentra√Ænement et √©valuation
# ----------------------------
resultats = []

for methode, pipeline in pipelines.items():
    print(f"\nüîç M√©thode : {methode}")

    if "SMOTE" in methode:
        tuned_parameters = param_grid_smote
    elif "UnderSampling" in methode:
        tuned_parameters = param_grid_under
    else:
        tuned_parameters = param_grid
    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)    
    grid = GridSearchCV(pipeline, tuned_parameters, cv=cv, scoring='f1', n_jobs=-1, error_score='raise')
    grid.fit(X_train, y_train)

    best_model = grid.best_estimator_
    y_pred = best_model.predict(X_val)
    y_proba = best_model.predict_proba(X_val)[:, 1]  # Probabilit√©s pour la classe 1

    resultats.append({
        'M√©thode': methode,
        'Accuracy': accuracy_score(y_val, y_pred),
        'Pr√©cision': precision_score(y_val, y_pred, zero_division=0),
        'Rappel': recall_score(y_val, y_pred),
        'F1-score': f1_score(y_val, y_pred),
        'ROC AUC': roc_auc_score(y_val, y_proba),
        'Best Params': grid.best_params_
    })

# ----------------------------
# 6. R√©sum√©
# ----------------------------
df_resultats = pd.DataFrame(resultats)
df_resultats = df_resultats.sort_values(by='F1-score', ascending=False).reset_index(drop=True)

print("\nüìä R√©sum√© des performances :")
print(df_resultats)







# Meilleurs hyperparam√®tres obtenus pour l'Arbre de D√©cision
best_params = df_resultats[df_resultats['M√©thode'] == 'Original']['Best Params'].values[0]
print("Meilleurs hyperparam√®tres : ", best_params)

# Reconstruire le pipeline final avec Arbre de D√©cision et original
best_pipeline_tree = ImbPipeline([
    ('preproc', preprocessor), 
    ('clf', DecisionTreeClassifier(
        criterion=best_params['clf__criterion'],  # Crit√®re pour l'arbre
        max_depth=best_params['clf__max_depth'],  # Profondeur maximale
        max_features=best_params['clf__max_features'],  # Nombre de caract√©ristiques √† consid√©rer pour chaque scission
        min_samples_leaf=best_params['clf__min_samples_leaf'],  # Nombre minimal d'√©chantillons par feuille
        min_samples_split=best_params['clf__min_samples_split'],  # Nombre minimal d'√©chantillons pour scinder un noeud
        random_state=best_params['clf__random_state']  # Fixer la graine pour la reproductibilit√©
    ))
])

# Entra√Æner le pipeline final
best_pipeline_tree.fit(X_train, y_train)




from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# 1. Pr√©dictions sur l'ensemble de test
y_pred = best_pipeline_tree.predict(X_val)

# 2. Matrice de confusion normalis√©e par ligne (pourcentage par classe r√©elle)
conf_matrix_normalized = confusion_matrix(y_val, y_pred, normalize='true') * 100  # en %

# 3. Affichage de la matrice de confusion normalis√©e en pourcentage
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix_normalized, annot=True, fmt='.3f', cmap='Blues',
            xticklabels=['Classe 0', 'Classe 1'],
            yticklabels=['Classe 0', 'Classe 1'])
plt.title('Matrice de Confusion Normalis√©e (par ligne, en %)')
plt.xlabel('Pr√©diction')
plt.ylabel('V√©rit√© terrain')
plt.show()

# 4. Affichage du rapport de classification
print("Rapport de classification :\n", classification_report(y_val, y_pred))



import dill

# Enregistrer le meilleur mod√®le avec dill
with open('best_Tree.dill', 'wb') as f:
    dill.dump(best_pipeline_tree, f)
    
# Charger le mod√®le avec dill
with open('best_Tree.dill', 'rb') as f:
    loaded_model = dill.load(f)
# Effectuer une pr√©diction pour tester le mod√®le charg√©
y_pred = loaded_model.predict(X_val)
print(y_pred)













from sklearn.ensemble import RandomForestClassifier
# ----------------------------
# 0. Baseline (mod√®le par d√©faut)
# ----------------------------
print("üìå Baseline : RandomForest sans tuning ni sampling")

baseline_pipeline = ImbPipeline([
    ('preproc', preprocessor),
    ('clf', RandomForestClassifier(random_state=42))
])

baseline_pipeline.fit(X_train, y_train)
y_pred_baseline = baseline_pipeline.predict(X_val)
y_proba_baseline = baseline_pipeline.predict_proba(X_val)[:, 1]

print("‚û°Ô∏è Performance du mod√®le baseline :")
print(f"Accuracy  : {accuracy_score(y_val, y_pred_baseline):.4f}")
print(f"Pr√©cision : {precision_score(y_val, y_pred_baseline, zero_division=0):.4f}")
print(f"Rappel    : {recall_score(y_val, y_pred_baseline):.4f}")
print(f"F1-score  : {f1_score(y_val, y_pred_baseline):.4f}")
print(f"ROC AUC   : {roc_auc_score(y_val, y_proba_baseline):.4f}")

print("\nüìã Hyperparam√®tres par d√©faut du RandomForest :")
for param, val in baseline_pipeline.named_steps['clf'].get_params().items():
    print(f"{param}: {val}")






from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from imblearn.pipeline import Pipeline as ImbPipeline
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import pandas as pd

# ----------------------------
# 1. S√©paration des variables
# ----------------------------
X = df.drop('FraudResult', axis=1)
y = df['FraudResult']

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)

# ----------------------------
# 2. Pr√©traitement dans un transformer unique
# ----------------------------
preprocessor = ColumnTransformer(transformers=[
    ('num', StandardScaler(), numeric_columns),
    ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_columns)
])

# ----------------------------
# 3. Param√®tres de recherche pour RandomForest
# ----------------------------
param_grid = {
    'clf__n_estimators': [200, 300],  # Nombre d'arbres
    'clf__max_depth': [10, 20],  # Profondeur maximale
    'clf__min_samples_split': [5, 10],  # Nombre minimal d'√©chantillons pour diviser un noeud
    'clf__min_samples_leaf': [2, 4],  # Nombre minimal d'√©chantillons dans une feuille
    'clf__max_features': [None],  # Nombre maximal de caract√©ristiques
    'clf__random_state': [42]  # Fixation de l'al√©a pour reproductibilit√©
}

# Param√®tres avec sur√©chantillonnage SMOTE
param_grid_smote = param_grid.copy()
param_grid_smote.update({
    'smote__sampling_strategy': [0.25, 0.5]
})

# Param√®tres avec sous-√©chantillonnage
param_grid_under = param_grid.copy()
param_grid_under.update({
    'under__sampling_strategy': [0.25, 0.5]
})


# ----------------------------
# 4. D√©finition des pipelines imbriqu√©s pour RandomForest
# ----------------------------
pipelines = {
    "RandomForest_Original": ImbPipeline([
        ('preproc', preprocessor),
        ('clf', RandomForestClassifier(random_state=42))
    ]),
    "RandomForest_SMOTE": ImbPipeline([
        ('preproc', preprocessor),
        ('smote', SMOTE(random_state=42)),
        ('clf', RandomForestClassifier(random_state=42))
    ]),
    "RandomForest_UnderSampling": ImbPipeline([
        ('preproc', preprocessor),
        ('under', RandomUnderSampler(random_state=42)),
        ('clf', RandomForestClassifier(random_state=42))
    ]),
    "Pond√©ration": ImbPipeline([
        ('preproc', preprocessor),
        ('clf', RandomForestClassifier(random_state=42, class_weight='balanced'))  # Pond√©ration des classes
   ])     
}

# ----------------------------
# 5. Boucle d‚Äôentra√Ænement et √©valuation pour RandomForest
# ----------------------------
resultats = []

for methode, pipeline in pipelines.items():
    print(f"\nüîç M√©thode : {methode}")

    if "SMOTE" in methode:
        tuned_parameters = param_grid_smote
    elif "UnderSampling" in methode:
        tuned_parameters = param_grid_under
    else:
        tuned_parameters = param_grid
    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)    
    grid = GridSearchCV(pipeline, tuned_parameters, cv=cv, scoring='f1', n_jobs=-1, error_score='raise')
    grid.fit(X_train, y_train)

    best_model = grid.best_estimator_
    y_pred = best_model.predict(X_val)
    y_proba = best_model.predict_proba(X_val)[:, 1]  # Probabilit√©s pour la classe 1

    resultats.append({
        'M√©thode': methode,
        'Accuracy': accuracy_score(y_val, y_pred),
        'Pr√©cision': precision_score(y_val, y_pred, zero_division=0),
        'Rappel': recall_score(y_val, y_pred),
        'F1-score': f1_score(y_val, y_pred),
        'ROC AUC': roc_auc_score(y_val, y_proba),
        'Best Params': grid.best_params_
    })

# ----------------------------
# 6. R√©sum√© des r√©sultats pour RandomForest
# ----------------------------
df_resultats = pd.DataFrame(resultats)
df_resultats = df_resultats.sort_values(by='F1-score', ascending=False).reset_index(drop=True)

print("\nüìä R√©sum√© des performances pour RandomForest :")
print(df_resultats)







# Meilleurs hyperparam√®tres obtenus pour l'Arbre de D√©cision
best_params = df_resultats[df_resultats['M√©thode'] == 'RandomForest_Original']['Best Params'].values[0]
print("Meilleurs hyperparam√®tres : ", best_params)

# Reconstruire le pipeline final avec Arbre de D√©cision et original
best_pipeline_RandomForest = ImbPipeline([
    ('preproc', preprocessor), 
    ('clf', RandomForestClassifier(
        n_estimators=best_params['clf__n_estimators'], 
        max_depth=best_params['clf__max_depth'], 
        max_features=best_params['clf__max_features'],  
        min_samples_leaf=best_params['clf__min_samples_leaf'], 
        min_samples_split=best_params['clf__min_samples_split'], 
        random_state=best_params['clf__random_state'] 
    ))
])

# Entra√Æner le pipeline final
best_pipeline_RandomForest.fit(X_train, y_train)




from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# 1. Pr√©dictions sur l'ensemble de test
y_pred = best_pipeline_RandomForest.predict(X_val)

# 2. Matrice de confusion normalis√©e par ligne (pourcentage par classe r√©elle)
conf_matrix_normalized = confusion_matrix(y_val, y_pred, normalize='true') * 100  # en %

# 3. Affichage de la matrice de confusion normalis√©e en pourcentage
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix_normalized, annot=True, fmt='.3f', cmap='Blues',
            xticklabels=['Classe 0', 'Classe 1'],
            yticklabels=['Classe 0', 'Classe 1'])
plt.title('Matrice de Confusion Normalis√©e (par ligne, en %)')
plt.xlabel('Pr√©diction')
plt.ylabel('V√©rit√© terrain')
plt.show()

# 4. Affichage du rapport de classification
print("Rapport de classification :\n", classification_report(y_val, y_pred))



import dill

# Enregistrer le meilleur mod√®le avec dill
with open('best_RandomForest.dill', 'wb') as f:
    dill.dump(best_pipeline_RandomForest, f)
    
# Charger le mod√®le avec dill
with open('best_RandomForest.dill', 'rb') as f:
    loaded_model = dill.load(f)
# Effectuer une pr√©diction pour tester le mod√®le charg√©
y_pred = loaded_model.predict(X_val)
print(y_pred)









from lightgbm import LGBMClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from imblearn.pipeline import Pipeline as ImbPipeline
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import pandas as pd

# ----------------------------
# 1. S√©paration des variables
# ----------------------------
X = df.drop('FraudResult', axis=1)
y = df['FraudResult']

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)

# ----------------------------
# 2. Pr√©traitement
# ----------------------------
preprocessor = ColumnTransformer(transformers=[
    ('num', StandardScaler(), numeric_columns),
    ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_columns)
])

# ----------------------------
# 0. Baseline (mod√®le par d√©faut)
# ----------------------------
print("üìå Baseline : LightGBM sans tuning ni sampling")

baseline_pipeline = ImbPipeline([
    ('preproc', preprocessor),
    ('clf', LGBMClassifier(random_state=42))
])

baseline_pipeline.fit(X_train, y_train)
y_pred_baseline = baseline_pipeline.predict(X_val)
y_proba_baseline = baseline_pipeline.predict_proba(X_val)[:, 1]

print("‚û°Ô∏è Performance du mod√®le baseline :")
print(f"Accuracy  : {accuracy_score(y_val, y_pred_baseline):.4f}")
print(f"Pr√©cision : {precision_score(y_val, y_pred_baseline, zero_division=0):.4f}")
print(f"Rappel    : {recall_score(y_val, y_pred_baseline):.4f}")
print(f"F1-score  : {f1_score(y_val, y_pred_baseline):.4f}")
print(f"ROC AUC   : {roc_auc_score(y_val, y_proba_baseline):.4f}")

# ----------------------------
# Affichage des hyperparam√®tres par d√©faut
# ----------------------------
print("\nüìã Hyperparam√®tres par d√©faut de LightGBM :")
for param, val in baseline_pipeline.named_steps['clf'].get_params().items():
    print(f"{param}: {val}")






from lightgbm import LGBMClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from imblearn.pipeline import Pipeline as ImbPipeline
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import pandas as pd

# ----------------------------
# 1. S√©paration des variables
# ----------------------------
X = df.drop('FraudResult', axis=1)
y = df['FraudResult']

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)

# ----------------------------
# 2. Pr√©traitement dans un transformer unique
# ----------------------------
preprocessor = ColumnTransformer(transformers=[
    ('num', StandardScaler(), numeric_columns),
    ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_columns)
])

# ----------------------------
# 3. Param√®tres de recherche pour LGBM
# ----------------------------
param_grid = {
    'clf__n_estimators': [200, 300],
    'clf__max_depth': [10, 20],
    'clf__learning_rate': [0.05, 0.2],
    'clf__num_leaves': [20, 40],
    'clf__random_state': [42]
}

# Param√®tres avec SMOTE
param_grid_smote = param_grid.copy()
param_grid_smote.update({
    'smote__sampling_strategy': [0.25, 0.5]
})

# Param√®tres avec sous-√©chantillonnage
param_grid_under = param_grid.copy()
param_grid_under.update({
    'under__sampling_strategy': [0.25, 0.5]
})

# ----------------------------
# 4. D√©finition des pipelines pour LGBM
# ----------------------------
pipelines = {
    "LightGBM_Original": ImbPipeline([
        ('preproc', preprocessor),
        ('clf', LGBMClassifier(random_state=42))
    ]),
    "LightGBM_SMOTE": ImbPipeline([
        ('preproc', preprocessor),
        ('smote', SMOTE(random_state=42)),
        ('clf', LGBMClassifier(random_state=42))
    ]),
    "LightGBM_UnderSampling": ImbPipeline([
        ('preproc', preprocessor),
        ('under', RandomUnderSampler(random_state=42)),
        ('clf', LGBMClassifier(random_state=42))
    ]),
    "Pond√©ration": ImbPipeline([
        ('preproc', preprocessor),
        ('clf', LGBMClassifier(random_state=42, class_weight='balanced'))
    ])
}

# ----------------------------
# 5. Boucle d‚Äôentra√Ænement et √©valuation pour LGBM
# ----------------------------
resultats = []

for methode, pipeline in pipelines.items():
    print(f"\nüîç M√©thode : {methode}")

    if "SMOTE" in methode:
        tuned_parameters = param_grid_smote
    elif "UnderSampling" in methode:
        tuned_parameters = param_grid_under
    else:
        tuned_parameters = param_grid
    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)    
    grid = GridSearchCV(pipeline, tuned_parameters, cv=cv, scoring='f1', n_jobs=-1, error_score='raise')
    grid.fit(X_train, y_train)

    best_model = grid.best_estimator_
    y_pred = best_model.predict(X_val)
    y_proba = best_model.predict_proba(X_val)[:, 1]

    resultats.append({
        'M√©thode': methode,
        'Accuracy': accuracy_score(y_val, y_pred),
        'Pr√©cision': precision_score(y_val, y_pred, zero_division=0),
        'Rappel': recall_score(y_val, y_pred),
        'F1-score': f1_score(y_val, y_pred),
        'ROC AUC': roc_auc_score(y_val, y_proba),
        'Best Params': grid.best_params_
    })

# ----------------------------
# 6. R√©sum√© des r√©sultats pour LGBM
# ----------------------------
df_resultats = pd.DataFrame(resultats)
df_resultats = df_resultats.sort_values(by='F1-score', ascending=False).reset_index(drop=True)

print("\nüìä R√©sum√© des performances pour LightGBM :")
print(df_resultats)






import lightgbm as lgb
from imblearn.pipeline import Pipeline as ImbPipeline  # Assure-toi d'importer la bonne classe Pipeline

# Meilleurs hyperparam√®tres obtenus pour LightGBM
best_params = df_resultats[df_resultats['M√©thode'] == 'LightGBM_SMOTE']['Best Params'].values[0]
print("Meilleurs hyperparam√®tres : ", best_params)

# Reconstruire le pipeline final avec LightGBM
best_pipeline_LightGBM = ImbPipeline([
    ('preproc', preprocessor),  
    ('smote', SMOTE(sampling_strategy=best_params['smote__sampling_strategy'])),  # Application de SMOTE
    ('clf', lgb.LGBMClassifier(
        learning_rate=best_params['clf__learning_rate'],  # Taux d'apprentissage
        max_depth=best_params['clf__max_depth'],          # Profondeur maximale des arbres
        n_estimators=best_params['clf__n_estimators'],    # Nombre d'arbres
        num_leaves=best_params['clf__num_leaves'],        # Nombre de feuilles par arbre
        random_state=best_params['clf__random_state']     # Pour la reproductibilit√©
    ))
])

# Entra√Æner le pipeline final
best_pipeline_LightGBM.fit(X_train, y_train)




from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# 1. Pr√©dictions sur l'ensemble de test
y_pred = best_pipeline_LightGBM.predict(X_val)

# 2. Matrice de confusion normalis√©e par ligne (pourcentage par classe r√©elle)
conf_matrix_normalized = confusion_matrix(y_val, y_pred, normalize='true') * 100  # en %

# 3. Affichage de la matrice de confusion normalis√©e en pourcentage
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix_normalized, annot=True, fmt='.3f', cmap='Blues',
            xticklabels=['Classe 0', 'Classe 1'],
            yticklabels=['Classe 0', 'Classe 1'])
plt.title('Matrice de Confusion Normalis√©e (par ligne, en %)')
plt.xlabel('Pr√©diction')
plt.ylabel('V√©rit√© terrain')
plt.show()

# 4. Affichage du rapport de classification
print("Rapport de classification :\n", classification_report(y_val, y_pred))


import dill

# Enregistrer le meilleur mod√®le avec dill
with open('best_SMOTE_LightGBM.dill', 'wb') as f:
    dill.dump(best_pipeline_LightGBM, f)
    
# Charger le mod√®le avec dill
with open('best_SMOTE_LightGBM.dill', 'rb') as f:
    loaded_model = dill.load(f)
# Effectuer une pr√©diction pour tester le mod√®le charg√©
y_pred = loaded_model.predict(X_val)
print(y_pred)












import shap
import dill
import numpy as np

# 1. Extraire les composants du pipeline
preprocessor = best_pipeline_LightGBM.named_steps['preproc']
model = best_pipeline_LightGBM.named_steps['clf']

# 2. Appliquer la transformation sur X_train
X_transformed = preprocessor.transform(X_train)

# 3. Convertir en array si n√©cessaire (utile si X_transformed est sparse)
if hasattr(X_transformed, 'toarray'):
    X_transformed = X_transformed.toarray()

# 4. R√©cup√©rer les noms de variables apr√®s transformation
feature_names = preprocessor.get_feature_names_out()

# 5. Cr√©er l'explainer SHAP pour le mod√®le LightGBM
explainer_LightGBM = shap.TreeExplainer(model)

# 6. Calculer les valeurs SHAP (d√©sactiver le check d‚Äôadditivit√© pour √©viter les erreurs)
shap_values_LightGBM = explainer_LightGBM(X_transformed, check_additivity=False)

# 7. Enregistrer les valeurs SHAP
with open('shap_values_LightGBM.dill', 'wb') as f:
    dill.dump(shap_values_LightGBM, f)

# 8. Recharger les valeurs SHAP
with open('shap_values_LightGBM.dill', 'rb') as f:
    loaded_shap_values_LightGBM = dill.load(f)

# 9. Visualisation globale (summary plot)
shap.summary_plot(loaded_shap_values_LightGBM, X_transformed, feature_names=feature_names)



import shap

# Recr√©er un nouvel objet Explanation avec les bons noms
shap_values_corrected = shap.Explanation(
    values=loaded_shap_values_LightGBM.values,
    base_values=loaded_shap_values_LightGBM.base_values,
    data=X_transformed,
    feature_names=feature_names
)

# Maintenant tu peux afficher le bar chart avec les bons noms
shap.plots.bar(shap_values_corrected, max_display=20)




