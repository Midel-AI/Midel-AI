


from pathlib import Path
import dill
import matplotlib.pyplot as plt
import missingno as msno
import numpy as np
import pandas as pd
import pendulum
import plotly.graph_objects as go
import plotly.express as px
import seaborn as sns
from imblearn.pipeline import Pipeline as imb_Pipeline
from loguru import logger
from sklearn import set_config
from sklearn.compose import make_column_transformer, ColumnTransformer
from sklearn.dummy import DummyClassifier
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (confusion_matrix,
                             classification_report,
                             ConfusionMatrixDisplay,
                             roc_auc_score,
                             accuracy_score,
                             precision_score,
                             recall_score,
                             f1_score,
                             RocCurveDisplay,
                             PrecisionRecallDisplay,
                            )
from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold
from sklearn.neighbors import KNeighborsClassifier
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, OrdinalEncoder, OneHotEncoder
from ucimlrepo import fetch_ucirepo, list_available_datasets
from yellowbrick.classifier import DiscriminationThreshold

set_config(display='diagram')
pd.set_option("display.max_columns", None)





HOME_DIR = Path("C:/Users/HP/Desktop/Livrables_groupe6/DATA")
DATA_TRAIN = HOME_DIR / "training.csv"
HOME_DIR.mkdir(parents=True, exist_ok=True)
print(f"Work directory: {HOME_DIR} \nData directory: {DATA_TRAIN}")


df = pd.read_csv(DATA_TRAIN, sep=";")
df.head()


df.tail()


df.shape


df.dtypes


df.info()


df.duplicated().sum()


df.isnull().sum()


df.describe(include = "all")





df['PricingStrategy'] = df['PricingStrategy'].astype('str')


df["FraudResult"].value_counts(normalize=False)


# Comptage des transactions frauduleuses et non frauduleuses
fraud_count = df[df["FraudResult"] == 1].shape[0]
non_fraud_count = df[df["FraudResult"] == 0].shape[0]

# Calcul des pourcentages
total = fraud_count + non_fraud_count
fraud_percentage = (fraud_count / total) * 100
non_fraud_percentage = (non_fraud_count / total) * 100

# Préparation des données pour le graphique
labels = ['Fraud', 'Non-Fraud']
sizes = [fraud_percentage, non_fraud_percentage]
colors = ['orange', 'skyblue']

# Création du graphique
fig, ax = plt.subplots(figsize=(8, 8))
ax.pie(sizes, labels=labels, autopct='%1.2f%%', startangle=90, colors=colors)

# Cercle central pour un effet "donut"
centre_circle = plt.Circle((0, 0), 0.70, fc='white')
fig.gca().add_artist(centre_circle)

# Titre du graphique
plt.title('Percentage of Fraud and Non-Fraud Transactions')
plt.show()



categorical_columns = df.select_dtypes(include="object").columns
categorical_columns


for col_name in categorical_columns:
    logger.info(f"{col_name} ==============\n {df[col_name].value_counts(dropna=False)}\n")


# Création des variables dérivées de AccountId, SubscriptionId, CustomerId
df['CustomerId_abs_amount_sum'] = df.groupby('CustomerId')['Amount'].transform(lambda x: x.abs().sum())
df['SubscriptionId_transaction_count'] = df.groupby('SubscriptionId')['TransactionId'].transform('count')
df['CustomerId_abs_amount_std'] = df.groupby('CustomerId')['Amount'].transform(lambda x: x.abs().std())
df['CustomerId_abs_amount_std'] = df['CustomerId_abs_amount_std'].fillna(0)


# Création des variables dérivées de TransactionStartTime
# Variable transaction_type (crédit ou débit)
df['TransactionType'] = df['Amount'].apply(lambda x: 'Credit' if x < 0 else 'Debit').astype('object')

# Conversion de la variable temporelle
df['TransactionStartTime'] = pd.to_datetime(df['TransactionStartTime'])

# Extraction des informations utiles
df['TransactionHour'] = df['TransactionStartTime'].dt.hour
df['TransactionDay'] = df['TransactionStartTime'].dt.day_name(locale='fr_FR')

# Création de la variable MomentOfDay
def get_moment(hour):
    if 6 <= hour < 13:
        return 'matin'
    elif 13 <= hour <= 20:
        return 'apres-midi'
    else:
        return 'nuit'

df['MomentOfDay'] = df['TransactionHour'].apply(get_moment)




# Vérifie si chaque ProductId correspond à une seule ProductCategory
mapping_check = df.groupby("ProductId")["ProductCategory"].nunique()
print("Nombre de ProductId ayant plus d'une catégorie :", (mapping_check > 1).sum())



# Certaines colonnes n’apportent pas d'information utile au modèle
cols_to_drop = ['TransactionId', 'BatchId', 'CustomerId','AccountId', 'SubscriptionId', 
                'CountryCode', 'CurrencyCode','TransactionStartTime','TransactionHour','ProductCategory']
df.drop(columns=cols_to_drop, inplace=True)





categorical_columns = df.select_dtypes(include="object").columns
categorical_columns


for col in categorical_columns:
    unique_col = df[col].unique();
    col_counts = df[col].value_counts()
    plt.figure(figsize=(16, 9))
    plt.xlabel(unique_col)
    plt.ylabel(col_counts)
    bars = col_counts.plot(kind='bar', color='skyblue')
    for bar in bars.patches:
        yval = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2, yval + 20000, f'{yval:,.0f}', ha='center', va='bottom', fontsize=10, color='black')
    plt.show()


# Recoder la variable ProduitId 
# Calculer la fréquence des produits
frequencies_product = df['ProductId'].value_counts(normalize=True) * 100

# Sélectionner les produits dont la fréquence dépasse 12%
products_above_12 = frequencies_product[frequencies_product > 12]
products_list = products_above_12.index.tolist()
def recode_product(X):
  try:
        if 'ProductId' in X.columns:
            X = X.copy()
            X['ProductId'] = X['ProductId'].apply(lambda x: x if x in products_list else 'Other')
        return X
  except:
        print("Vérifier la liste des colonnes")

df = recode_product(df)

df['ProductId'].value_counts().plot(kind='pie',autopct='%1.1f%%')
plt.title('ProductId')
plt.axis('equal')
plt.show()



# Recoder la variable providerID 
frequencies_provider = df['ProviderId'].value_counts(normalize=True) * 100

# Sélectionner les provider dont la fréquence dépasse 12%
provider_above_12 = frequencies_provider[frequencies_provider > 12]

provider_list = provider_above_12.index.tolist()

def recode_provider(X):
  try:
        if 'ProviderId' in X.columns:
            X = X.copy()
            X['ProviderId'] = X['ProviderId'].apply(lambda x: x if x in provider_list else 'Other')
        return X
  except:
        print("Vérifier la liste des colonnes")

df = recode_provider(df)

df['ProviderId'].value_counts().plot(kind='pie',autopct='%1.1f%%')
plt.title('ProviderId')
plt.axis('equal')
plt.show()



# Recoder la variable ChannelId

channel_list = ['ChannelId_2','ChannelId_3']
def recode_channel(X):
  try:
        if 'ChannelId' in X.columns:
            X = X.copy()
            X['ChannelId'] = X['ChannelId'].apply(lambda x: x if x in channel_list else 'Other')
        return X
  except:
        print("Vérifier la liste des colonnes")

df = recode_channel(df)

# Visualiser
df['ChannelId'].value_counts().plot(kind='pie',autopct='%1.1f%%')
plt.title('ChannelId')
plt.axis('equal')
plt.show()



# Recoder la variable PricingStrategy
Pricing_list = ["2","4"]

def recode_pricing(X):
  try:
        if 'PricingStrategy' in X.columns:
            X = X.copy()
            X['PricingStrategy'] = X['PricingStrategy'].apply(lambda x: x if x in Pricing_list else 'Other')
        return X
  except:
        print("Vérifier la liste des colonnes")

df = recode_pricing(df)

# Visualiser
df['PricingStrategy'].value_counts().plot(kind='pie',autopct='%1.1f%%')
plt.title('PricingStrategy')
plt.axis('equal')
plt.show()






numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns
numeric_columns = [col for col in numeric_columns if col != 'FraudResult']
numeric_columns


# Initialize a figure
fig = go.Figure()

# Iterate over numeric columns in the DataFrame
for column in numeric_columns:
    fig.add_trace(go.Box(
        y=df[column],
        name=column,
        marker=dict(color='skyblue')
    ))

# Update layout with a title and axis labels
fig.update_layout(
    title='Distribution of Numeric Columns',
    yaxis_title='Values',
    xaxis_title='Numeric Columns'
)

# Show the figure
fig.show()



import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Créer les colonnes log si elles n'existent pas
df['log_Value'] = np.log1p(df['Value'])  # log1p pour éviter log(0)
df['log_abs_Amount'] = np.log1p(df['Amount'].abs())
df['log_CustomerId_abs_amount_sum'] = np.log1p(df['CustomerId_abs_amount_sum'])

# Créer la figure
fig, axes = plt.subplots(1, 6, figsize=(18, 6))

# Tracer les boîtes
sns.boxplot(y=df['Value'], ax=axes[0], color='skyblue')
axes[0].set_title("Value")

sns.boxplot(y=df['log_Value'], ax=axes[1], color='lightgreen')
axes[1].set_title("log(Value)")

sns.boxplot(y=df['Amount'], ax=axes[2], color='salmon')
axes[2].set_title("Amount")

sns.boxplot(y=df['log_abs_Amount'], ax=axes[3], color='violet')
axes[3].set_title("log(|Amount|)")

sns.boxplot(y=df['CustomerId_abs_amount_sum'], ax=axes[4], color='skyblue')
axes[4].set_title("CustomerId_abs_amount_sum")
                                               
sns.boxplot(y=df['log_CustomerId_abs_amount_sum'], ax=axes[5], color='salmon')
axes[5].set_title("log_CustomerId_abs_amount_sum")

                                               
plt.tight_layout()
plt.show()


import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Créer la figure avec 4 subplots en ligne
fig, axes = plt.subplots(1, 6, figsize=(20, 5))

# Tracer chaque distribution
sns.histplot(df['Value'], kde=True, color='lightgreen', ax=axes[0])
axes[0].set_title("Value")
axes[0].set_ylim(0, 590) 

sns.histplot(df['log_Value'], kde=True, color='lightgreen', ax=axes[1])
axes[1].set_title("log(Value)")

sns.histplot(df['Amount'], kde=True, color='violet', ax=axes[2])
axes[2].set_title("Amount")
axes[2].set_ylim(0, 150)  

sns.histplot(df['log_abs_Amount'], kde=True, color='violet', ax=axes[3])
axes[3].set_title("log(|Amount|)")

sns.histplot(df['CustomerId_abs_amount_sum'], kde=True, color='salmon', ax=axes[4])
axes[4].set_title("CustomerId_abs_amount_sum")

sns.histplot(df['log_CustomerId_abs_amount_sum'], kde=True, color='salmon', ax=axes[5])
axes[5].set_title("log_CustomerId_abs_amount_sum")

plt.tight_layout()
plt.show()






from scipy.stats import chi2_contingency
import numpy as np
import pandas as pd

var_names = []
chi2_scores = []
p_values = []
cramer_vs = []

for var in categorical_columns:
    contingency_table = pd.crosstab(df['FraudResult'], df[var])
    chi2, p, dof, expected = chi2_contingency(contingency_table)

    # Calcul du nombre total d'observations
    n = contingency_table.values.sum()
    k, r = contingency_table.shape

    # Calcul corrigé du V de Cramér
    cramer_v = np.sqrt(chi2 / (n * (min(k - 1, r - 1))))

    # Stockage des résultats
    var_names.append(var)
    chi2_scores.append(chi2)
    p_values.append(p)
    cramer_vs.append(cramer_v)

# Résultat final sous forme de DataFrame
resultats = pd.DataFrame({
    'Variable': var_names,
    'Chi2': chi2_scores,
    'P-value': p_values,
    'Cramer V': cramer_vs
})

# Affichage des résultats
print(resultats.sort_values(by='Cramer V', ascending=False))




fraud_transactions = df[df["FraudResult"] == 1]
for col in categorical_columns:
    fraud_counts_by_columns = fraud_transactions.groupby(col).size()
    plt.figure(figsize=(8, 8))
    plt.pie(fraud_counts_by_columns, labels=fraud_counts_by_columns.index , autopct='%1.1f%%', startangle=90)
    plt.title(f'Proportion of Fraud Transactions by {col}')
    plt.show()



for col_name in categorical_columns:
    feature_FraudResult_counts = df.groupby([col_name, 'FraudResult']).size().unstack()
    
    fig = px.bar(feature_FraudResult_counts,
                 barmode='stack',  # Stack bars for income categories
                 title=f'Relationship between FraudResult and {col_name}',
                 labels={'value': 'Count'}
                )
    fig.show()





# Création de la colonne "Ecart" entre Amount et Value
df['Amount_Value_Ecart'] = df['Value'] - df['Amount'].abs()

poids_non_fraud = (95469 + 193) / 95469  # Poids pour la classe non frauduleuse
poids_fraud = (95469 + 193) / 193        # Poids pour la classe frauduleuse

# Ajout des poids dans le DataFrame
df['Weight'] = df['FraudResult'].apply(lambda x: poids_fraud if x == 1 else poids_non_fraud)

# Séparation des données par classe FraudResult
fraud_df = df[df['FraudResult'] == 1]
non_fraud_df = df[df['FraudResult'] == 0]

# Calcul des statistiques descriptives de l'écart avec pondération
fraud_weighted = fraud_df[['Amount_Value_Ecart', 'Weight']].apply(lambda x: x['Amount_Value_Ecart'] * x['Weight'], axis=1).sum() / fraud_df['Weight'].sum()
non_fraud_weighted = non_fraud_df[['Amount_Value_Ecart', 'Weight']].apply(lambda x: x['Amount_Value_Ecart'] * x['Weight'], axis=1).sum() / non_fraud_df['Weight'].sum()

# Affichage des résultats
print(f"Écart moyen pondéré (Frauduleuses) : {fraud_weighted}")
print(f"Écart moyen pondéré (Non Frauduleuses) : {non_fraud_weighted}")

# Comparaison graphique avec pondération
plt.figure(figsize=(12, 6))
sns.kdeplot(fraud_df['Amount_Value_Ecart'], label='Frauduleuses')
sns.kdeplot(non_fraud_df['Amount_Value_Ecart'], label='Non frauduleuses')
plt.title("Comparaison de l'écart pondéré entre Amount et Value (Frauduleuses vs Non frauduleuses)")
plt.xlabel("Ecart (|Amount - Value|)")
plt.ylabel("Densité")
plt.legend()
plt.show()
# conclusion : L'écart entre Amount et Value semble être un bon indicateur pour distinguer les transactions frauduleuses des transactions non frauduleuses
df.drop(columns="Weight", inplace=True)


numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns
numeric_columns = [col for col in numeric_columns if col != 'FraudResult']
numeric_columns


from scipy import stats

var_names = []
f_stat_values_fraud = []
p_values_fraud = []
f_stat_values_non_fraud = []
p_values_non_fraud = []

for var in numeric_columns:
    # Groupes pour les transactions non frauduleuses et frauduleuses
    group1 = df[df['FraudResult'] == 0][var]  # Non-fraudulent transactions
    group2 = df[df['FraudResult'] == 1][var]  # Fraudulent transactions

    # Test ANOVA pour comparer les deux groupes (fraude et non fraude)
    f_stat, p = stats.f_oneway(group1, group2)

    # Ajouter les résultats pour chaque variable
    var_names.append(var)
    f_stat_values_fraud.append(f_stat)
    p_values_fraud.append(p)
    f_stat_values_non_fraud.append(f_stat)  # Même F-statistique pour les deux groupes
    p_values_non_fraud.append(p)           # Même p-value pour les deux groupes

# Création d'un DataFrame avec les résultats
resultats = pd.DataFrame({
    'Variable': var_names,
    'F-Statistic (Fraud vs Non-Fraud)': f_stat_values_fraud,
    'P-value (Fraud vs Non-Fraud)': p_values_fraud
})

resultats



import scipy.stats as stats
import pandas as pd

var_names = []
ks_stat_nonfraud = []
p_values_nonfraud = []
ks_stat_fraud = []
p_values_fraud = []

for var in numeric_columns:
    # Groupe non frauduleux
    group_nonfraud = df[df['FraudResult'] == 0][var]
    group_nonfraud_std = (group_nonfraud - group_nonfraud.mean()) / group_nonfraud.std()
    ks_nonfraud = stats.kstest(group_nonfraud_std, 'norm')
    
    # Groupe frauduleux
    group_fraud = df[df['FraudResult'] == 1][var]
    group_fraud_std = (group_fraud - group_fraud.mean()) / group_fraud.std()
    ks_fraud = stats.kstest(group_fraud_std, 'norm')
    
    # Stocker les résultats
    var_names.append(var)
    ks_stat_nonfraud.append(ks_nonfraud.statistic)
    p_values_nonfraud.append(ks_nonfraud.pvalue)
    ks_stat_fraud.append(ks_fraud.statistic)
    p_values_fraud.append(ks_fraud.pvalue)

# Créer le DataFrame des résultats
resultats = pd.DataFrame({
    'Variable': var_names,
    'KS Stat (Non Fraude)': ks_stat_nonfraud,
    'P-value (Non Fraude)': p_values_nonfraud,
    'KS Stat (Fraude)': ks_stat_fraud,
    'P-value (Fraude)': p_values_fraud
})

resultats



# Certaines colonnes n’apportent plus d'information utile au modèle
cols_to_drop = ['Amount', 'log_Value', 'log_abs_Amount','CustomerId_abs_amount_sum']
df.drop(columns=cols_to_drop, inplace=True)


numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns
numeric_columns = [col for col in numeric_columns if col != 'FraudResult']
numeric_columns



import seaborn as sns
import matplotlib.pyplot as plt


# Créer une figure pour afficher les graphiques
plt.figure(figsize=(12, 6))

# Boucle sur les variables à visualiser
for i, var in enumerate(numeric_columns):
    plt.subplot(3, 2, i + 1)
    
    # Tracer les histogrammes et les courbes de densité
    sns.histplot(data=df, x=var, hue="FraudResult", kde=True, stat="density", common_norm=False, bins=30)
    
    # Ajouter des labels et un titre
    plt.title(f'Distribution de {var} par type de transaction')
    plt.xlabel(var)
    plt.ylabel('Density')
    
plt.tight_layout()
plt.show()




for column in numeric_columns:
    fig = px.box(
        data_frame=df,
        x='FraudResult',  
        y=column,
        title=f"Distribution de {column} par FraudResult",
        labels={'FraudResult': 'Résultat', column: column}
    )
    fig.show()



# Combiner 'numeric_columns' et 'FraudResult' dans une seule liste
columns_to_select = numeric_columns + ['FraudResult']

# Utiliser la liste résultante pour sélectionner les colonnes et générer le pairplot
sns.pairplot(df[columns_to_select], hue="FraudResult", corner=False)






correlation = df[numeric_columns].corr(method="pearson")


# correlation plot
plt.figure(figsize=(10, 7))
corr = df[numeric_columns].corr(method="pearson")
mask = np.zeros_like(corr)
mask[np.triu_indices_from(mask)] = True

sns.heatmap(corr, cmap='Greens', annot=True, square=True,
            fmt='.3f',
            mask=mask,
            cbar=True, vmin=-1, vmax=1);
