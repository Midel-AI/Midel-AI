


from pathlib import Path
import dill
import matplotlib.pyplot as plt
import missingno as msno
import numpy as np
import pandas as pd
import pendulum
import plotly.graph_objects as go
import plotly.express as px
import seaborn as sns
from imblearn.pipeline import Pipeline as imb_Pipeline
from loguru import logger
from sklearn import set_config
from sklearn.compose import make_column_transformer, ColumnTransformer
from sklearn.dummy import DummyClassifier
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (confusion_matrix,
                             classification_report,
                             ConfusionMatrixDisplay,
                             roc_auc_score,
                             accuracy_score,
                             precision_score,
                             recall_score,
                             f1_score,
                             RocCurveDisplay,
                             PrecisionRecallDisplay,
                            )
from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold
from sklearn.neighbors import KNeighborsClassifier
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, OrdinalEncoder, OneHotEncoder
from ucimlrepo import fetch_ucirepo, list_available_datasets
from yellowbrick.classifier import DiscriminationThreshold

set_config(display='diagram')
pd.set_option("display.max_columns", None)





HOME_DIR = Path("C:/Users/HP/Desktop/Livrables_groupe6/DATA")
DATA_TRAIN = HOME_DIR / "training.csv"
HOME_DIR.mkdir(parents=True, exist_ok=True)
print(f"Work directory: {HOME_DIR} \nData directory: {DATA_TRAIN}")











from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from imblearn.pipeline import Pipeline as ImbPipeline
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import pandas as pd

# ----------------------------
# 1. S√©paration des variables
# ----------------------------
X = df.drop('FraudResult', axis=1)
y = df['FraudResult']

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)

# ----------------------------
# 2. Pr√©traitement
# ----------------------------
preprocessor = ColumnTransformer(transformers=[
    ('num', StandardScaler(), numeric_columns),
    ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_columns)
])

# ----------------------------
# 0. Baseline (mod√®le par d√©faut)
# ----------------------------
print("üìå Baseline : R√©gression Logistique sans tuning ni sampling")

baseline_pipeline = ImbPipeline([
    ('preproc', preprocessor),
    ('clf', LogisticRegression(random_state=42))
])

baseline_pipeline.fit(X_train, y_train)
y_pred_baseline = baseline_pipeline.predict(X_val)
y_proba_baseline = baseline_pipeline.predict_proba(X_val)[:, 1]

print("‚û°Ô∏è Performance du mod√®le baseline :")
print(f"Accuracy  : {accuracy_score(y_val, y_pred_baseline):.4f}")
print(f"Pr√©cision : {precision_score(y_val, y_pred_baseline, zero_division=0):.4f}")
print(f"Rappel    : {recall_score(y_val, y_pred_baseline):.4f}")
print(f"F1-score  : {f1_score(y_val, y_pred_baseline):.4f}")
print(f"ROC AUC   : {roc_auc_score(y_val, y_proba_baseline):.4f}")
# ----------------------------
# Affichage des hyperparam√®tres par d√©faut
# ----------------------------
print("\nüìã Hyperparam√®tres par d√©faut de la R√©gression Logistique :")
for param, val in baseline_pipeline.named_steps['clf'].get_params().items():
    print(f"{param}: {val}")






from sklearn.model_selection import GridSearchCV, StratifiedKFold
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from imblearn.pipeline import Pipeline as ImbPipeline
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import pandas as pd

# ----------------------------
# 1. S√©paration des variables
# ----------------------------
X = df.drop('FraudResult', axis=1)
y = df['FraudResult']

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)

# ----------------------------
# 2. Pr√©traitement dans un transformer unique
# ----------------------------
preprocessor = ColumnTransformer(transformers=[
    ('num', StandardScaler(), numeric_columns),
    ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_columns)
])

# ----------------------------
# 3. Param√®tres de recherche pour RandomForest et sampling
# ----------------------------
# Param√®tres de base du classifieur
param_grid = {
    'clf__penalty': ['l2'],
    'clf__C': [0.1, 10],
    'clf__solver': ['lbfgs'],
    'clf__max_iter': [6000]
}

# Param√®tres avec sur√©chantillonnage SMOTE
param_grid_smote = param_grid.copy()
param_grid_smote.update({
    'smote__sampling_strategy': [0.25, 0.5]
})

# Param√®tres avec sous-√©chantillonnage
param_grid_under = param_grid.copy()
param_grid_under.update({
    'under__sampling_strategy': [0.25, 0.5]
})

# ----------------------------
# 4. Pipelines avec diff√©rentes m√©thodes
# ----------------------------
pipelines = {
    "Original": ImbPipeline([
        ('preproc', preprocessor),
        ('clf', LogisticRegression())
    ]),
    "SMOTE": ImbPipeline([
        ('preproc', preprocessor),
        ('smote', SMOTE(random_state=42)),
        ('clf', LogisticRegression())
    ]),
    "UnderSampling": ImbPipeline([
        ('preproc', preprocessor),
        ('under', RandomUnderSampler(random_state=42)),
        ('clf', LogisticRegression())
    ]),
    "Pond√©ration": ImbPipeline([
        ('preproc', preprocessor),
        ('clf', LogisticRegression(class_weight='balanced'))
    ])
}

# ----------------------------
# 5. Entra√Ænement et √©valuation
# ----------------------------
resultats = []


for methode, pipeline in pipelines.items():
    print(f"\nüîç M√©thode : {methode}")

    if "SMOTE" in methode:
        tuned_parameters = param_grid_smote
    elif "UnderSampling" in methode:
        tuned_parameters = param_grid_under
    else:
        tuned_parameters = param_grid
    
    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)    
    grid = GridSearchCV(pipeline, tuned_parameters, cv=cv, scoring='f1', n_jobs=-1, error_score='raise')
    grid.fit(X_train, y_train)

    
    best_model = grid.best_estimator_
    y_pred = best_model.predict(X_val)
    y_proba = best_model.predict_proba(X_val)[:, 1]

    resultats.append({
        'M√©thode': methode,
        'Accuracy': accuracy_score(y_val, y_pred),
        'Pr√©cision': precision_score(y_val, y_pred, zero_division=0),
        'Rappel': recall_score(y_val, y_pred),
        'F1-score': f1_score(y_val, y_pred),
        'ROC AUC': roc_auc_score(y_val, y_proba),
        'Best Params': grid.best_params_
    })

# ----------------------------
# 6. R√©sum√© des r√©sultats
# ----------------------------
df_resultats = pd.DataFrame(resultats)
df_resultats = df_resultats.sort_values(by='F1-score', ascending=False).reset_index(drop=True)

print("\nüìä R√©sum√© des performances pour regression logistique:")
print(df_resultats)






# Recr√©er le pipeline avec les meilleurs param√®tres
from sklearn.linear_model import LogisticRegression
from imblearn.pipeline import Pipeline as ImbPipeline
from imblearn.under_sampling import RandomUnderSampler

# Meilleurs hyperparam√®tres
best_params = df_resultats[df_resultats['M√©thode'] == 'UnderSampling']['Best Params'].values[0]
# Reconstruire le pipeline final
best_pipeline_regressin_logistique = ImbPipeline([
    ('preproc', preprocessor),
    ('under', RandomUnderSampler(sampling_strategy=best_params['under__sampling_strategy'], random_state=42)),
    ('clf', LogisticRegression(
        penalty=best_params['clf__penalty'],
        C=best_params['clf__C'],
        solver=best_params['clf__solver'],
        max_iter=best_params['clf__max_iter']
    ))
])


# Entra√Æner le pipeline final
print("best hyperam", best_params)
best_pipeline_regressin_logistique.fit(X_train, y_train)



from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt

# 1. Pr√©dictions du mod√®le
y_pred = best_pipeline_regressin_logistique.predict(X_val)

# 2. Matrice de confusion normalis√©e par ligne (pourcentage par classe r√©elle)
conf_matrix_normalized = confusion_matrix(y_val, y_pred, normalize='true') * 100  # en %

# 3. Affichage de la matrice de confusion normalis√©e
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix_normalized, annot=True, fmt='.3f', cmap='Blues',
            xticklabels=['Classe 0', 'Classe 1'],
            yticklabels=['Classe 0', 'Classe 1'])
plt.title('Matrice de Confusion Normalis√©e (par ligne, en %)')
plt.xlabel('Pr√©diction')
plt.ylabel('V√©rit√© terrain')
plt.show()

# 4. Affichage du rapport de classification
print("Rapport de classification :\n", classification_report(y_val, y_pred))



import dill

# Enregistrer le meilleur mod√®le avec dill
with open('best_Regression_logistique.dill', 'wb') as f:
    dill.dump(best_pipeline_regressin_logistique, f)
    
# Charger le mod√®le avec dill
with open('best_Regression_logistique.dill', 'rb') as f:
    loaded_model = dill.load(f)
# Effectuer une pr√©diction pour tester le mod√®le charg√©
y_pred = loaded_model.predict(X_val)
print(y_pred)









from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from imblearn.pipeline import Pipeline as ImbPipeline
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import pandas as pd

# ----------------------------
# 1. S√©paration des variables
# ----------------------------
X = df.drop('FraudResult', axis=1)
y = df['FraudResult']

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)

# ----------------------------
# 2. Pr√©traitement
# ----------------------------
preprocessor = ColumnTransformer(transformers=[
    ('num', StandardScaler(), numeric_columns),
    ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_columns)
])

# ----------------------------
# 0. Baseline (mod√®le par d√©faut)
# ----------------------------
print("üìå Baseline : K-Nearest Neighbors sans tuning ni sampling")

baseline_pipeline = ImbPipeline([
    ('preproc', preprocessor),
    ('clf', KNeighborsClassifier())
])

baseline_pipeline.fit(X_train, y_train)
y_pred_baseline = baseline_pipeline.predict(X_val)
y_proba_baseline = baseline_pipeline.predict_proba(X_val)[:, 1]

print("‚û°Ô∏è Performance du mod√®le baseline :")
print(f"Accuracy  : {accuracy_score(y_val, y_pred_baseline):.4f}")
print(f"Pr√©cision : {precision_score(y_val, y_pred_baseline, zero_division=0):.4f}")
print(f"Rappel    : {recall_score(y_val, y_pred_baseline):.4f}")
print(f"F1-score  : {f1_score(y_val, y_pred_baseline):.4f}")
print(f"ROC AUC   : {roc_auc_score(y_val, y_proba_baseline):.4f}")

# ----------------------------
# Affichage des hyperparam√®tres par d√©faut
# ----------------------------
print("\nüìã Hyperparam√®tres par d√©faut de K-Nearest Neighbors :")
for param, val in baseline_pipeline.named_steps['clf'].get_params().items():
    print(f"{param}: {val}")






from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from imblearn.pipeline import Pipeline as ImbPipeline
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import pandas as pd

# ----------------------------
# 1. S√©paration des variables
# ----------------------------
X = df.drop('FraudResult', axis=1)
y = df['FraudResult']

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)

# ----------------------------
# 2. Pr√©traitement dans un transformer unique
# ----------------------------
preprocessor = ColumnTransformer(transformers=[
    ('num', StandardScaler(), numeric_columns),
    ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_columns)
])

# ----------------------------
# 3. Param√®tres de recherche pour KNN et sampling
# ----------------------------
# Param√®tres de base du classifieur KNN
param_grid = {
    'clf__n_neighbors': [3, 10],
    'clf__metric': ['minkowski', 'euclidean'],
    'clf__weights': ['uniform', 'distance'],
}

# Param√®tres avec sur√©chantillonnage SMOTE
param_grid_smote = param_grid.copy()
param_grid_smote.update({
    'smote__sampling_strategy': [0.25, 0.5]
})

# Param√®tres avec sous-√©chantillonnage
param_grid_under = param_grid.copy()
param_grid_under.update({
    'under__sampling_strategy': [0.25, 0.5]
})

# ----------------------------
# 4. Pipelines avec diff√©rentes m√©thodes
# ----------------------------
pipelines = {
    "Original": ImbPipeline([
        ('preproc', preprocessor),
        ('clf', KNeighborsClassifier())
    ]),
    "SMOTE": ImbPipeline([
        ('preproc', preprocessor),
        ('smote', SMOTE(random_state=42)),
        ('clf', KNeighborsClassifier())
    ]),
    "UnderSampling": ImbPipeline([
        ('preproc', preprocessor),
        ('under', RandomUnderSampler(random_state=42)),
        ('clf', KNeighborsClassifier())
    ]),
    "Pond√©ration": ImbPipeline([
        ('preproc', preprocessor),
        ('clf', KNeighborsClassifier(weights='uniform'))  # "uniform" pour l'√©quilibre des poids
    ])
}

# ----------------------------
# 5. Entra√Ænement et √©valuation
# ----------------------------
resultats_knn = []

for methode, pipeline in pipelines.items():
    print(f"\nüîç M√©thode : {methode}")

    if "SMOTE" in methode:
        tuned_parameters = param_grid_smote
    elif "UnderSampling" in methode:
        tuned_parameters = param_grid_under
    else:
        tuned_parameters = param_grid
    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)    
    grid = GridSearchCV(pipeline, tuned_parameters, cv=cv, scoring='f1', n_jobs=-1, error_score='raise')
    grid.fit(X_train, y_train)
    best_model = grid.best_estimator_
    y_pred = best_model.predict(X_val)
    y_proba = best_model.predict_proba(X_val)[:, 1]

    resultats_knn.append({
        'M√©thode': methode,
        'Accuracy': accuracy_score(y_val, y_pred),
        'Pr√©cision': precision_score(y_val, y_pred, zero_division=0),
        'Rappel': recall_score(y_val, y_pred),
        'F1-score': f1_score(y_val, y_pred),
        'ROC AUC': roc_auc_score(y_val, y_proba),
        'Best Params': grid.best_params_
    })

# ----------------------------
# 6. R√©sum√© des r√©sultats
# ----------------------------
df_resultats_knn = pd.DataFrame(resultats_knn)
df_resultats_knn = df_resultats_knn.sort_values(by='F1-score', ascending=False).reset_index(drop=True)

print("\nüìä R√©sum√© des performances pour K-Nearest Neighbors :")
print(df_resultats_knn)






from imblearn.pipeline import Pipeline as ImbPipeline
from imblearn.over_sampling import SMOTE
from sklearn.neighbors import KNeighborsClassifier

# Meilleurs hyperparam√®tres obtenus par SMOTE
best_params = df_resultats_knn[df_resultats_knn['M√©thode'] == 'SMOTE']['Best Params'].values[0]
# Reconstruire le pipeline final avec SMOTE et KNN
best_pipeline_KNN= ImbPipeline([
    ('preproc', preprocessor),
    ('smote', SMOTE(sampling_strategy=best_params['smote__sampling_strategy'], random_state=42)),
    ('clf', KNeighborsClassifier(
        n_neighbors=best_params['clf__n_neighbors'],
        weights=best_params['clf__weights']

    ))
])
print("best hyperparam", best_params)
# Entra√Æner le pipeline final
best_pipeline_KNN.fit(X_train, y_train)



from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# 1. Pr√©dictions du mod√®le
y_pred = best_pipeline_KNN.predict(X_val)

# 2. Matrice de confusion normalis√©e par ligne (pourcentage par classe r√©elle)
conf_matrix_normalized = confusion_matrix(y_val, y_pred, normalize='true') * 100  # en %

# 3. Affichage de la matrice de confusion en pourcentage (ligne)
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix_normalized, annot=True, fmt='.3f', cmap='Blues',
            xticklabels=['Classe 0', 'Classe 1'],
            yticklabels=['Classe 0', 'Classe 1'])
plt.title('Matrice de Confusion Normalis√©e (par ligne, en %)')
plt.xlabel('Pr√©diction')
plt.ylabel('V√©rit√© terrain')
plt.show()

# 4. Rapport de classification
print("Rapport de classification :\n", classification_report(y_val, y_pred))




import dill

# Enregistrer le meilleur mod√®le avec dill
with open('best_KNN.dill', 'wb') as f:
    dill.dump(best_pipeline_KNN, f)
    
# Charger le mod√®le avec dill
with open('best_KNN.dill', 'rb') as f:
    loaded_model = dill.load(f)
# Effectuer une pr√©diction pour tester le mod√®le charg√©
y_pred = loaded_model.predict(X_val)
print(y_pred)









from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from imblearn.pipeline import Pipeline as ImbPipeline
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import pandas as pd

# ----------------------------
# 1. S√©paration des variables
# ----------------------------
X = df.drop('FraudResult', axis=1)
y = df['FraudResult']

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)

# ----------------------------
# 2. Pr√©traitement
# ----------------------------
preprocessor = ColumnTransformer(transformers=[
    ('num', StandardScaler(), numeric_columns),
    ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_columns)
])

# ----------------------------
# 0. Baseline (mod√®le par d√©faut)
# ----------------------------
print("üìå Baseline : Decision Tree sans tuning ni sampling")

baseline_pipeline = ImbPipeline([
    ('preproc', preprocessor),
    ('clf', DecisionTreeClassifier(random_state=42))
])

baseline_pipeline.fit(X_train, y_train)
y_pred_baseline = baseline_pipeline.predict(X_val)
y_proba_baseline = baseline_pipeline.predict_proba(X_val)[:, 1]

print("‚û°Ô∏è Performance du mod√®le baseline :")
print(f"Accuracy  : {accuracy_score(y_val, y_pred_baseline):.4f}")
print(f"Pr√©cision : {precision_score(y_val, y_pred_baseline, zero_division=0):.4f}")
print(f"Rappel    : {recall_score(y_val, y_pred_baseline):.4f}")
print(f"F1-score  : {f1_score(y_val, y_pred_baseline):.4f}")
print(f"ROC AUC   : {roc_auc_score(y_val, y_proba_baseline):.4f}")

# ----------------------------
# Affichage des hyperparam√®tres par d√©faut
# ----------------------------
print("\nüìã Hyperparam√®tres par d√©faut de Decision Tree :")
for param, val in baseline_pipeline.named_steps['clf'].get_params().items():
    print(f"{param}: {val}")






from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from imblearn.pipeline import Pipeline as ImbPipeline
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import pandas as pd

# ----------------------------
# 1. S√©paration des variables
# ----------------------------
X = df.drop('FraudResult', axis=1)
y = df['FraudResult']

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)

# ----------------------------
# 2. Pr√©traitement dans un transformer unique
# ----------------------------
preprocessor = ColumnTransformer(transformers=[
    ('num', StandardScaler(), numeric_columns),
    ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_columns)
])

# ----------------------------
# 3. Param√®tres de recherche pour Decision Tree
# ----------------------------
param_grid = {
    'clf__criterion': ['gini', 'entropy'],  # Crit√®re de d√©cision
    'clf__max_depth': [5, 10],  # Profondeur maximale de l'arbre
    'clf__min_samples_split': [4, 8],  # Nombre minimal d'√©chantillons pour diviser un noeud
    'clf__min_samples_leaf': [3, 7],  # Nombre minimal d'√©chantillons dans une feuille
    'clf__max_features': [None, 'sqrt'],  # Nombre maximal de caract√©ristiques √† consid√©rer
    'clf__random_state': [42]  # Fixation de l'al√©a pour reproductibilit√©
}

# Param√®tres avec sur√©chantillonnage SMOTE
param_grid_smote = param_grid.copy()
param_grid_smote.update({
    'smote__sampling_strategy': [0.25, 0.5]
})

# Param√®tres avec sous-√©chantillonnage
param_grid_under = param_grid.copy()
param_grid_under.update({
    'under__sampling_strategy': [0.25, 0.5]
})


# ----------------------------
# 4. D√©finition des pipelines imbriqu√©s
# ----------------------------
pipelines = {
    "Original": ImbPipeline([
        ('preproc', preprocessor),
        ('clf', DecisionTreeClassifier(random_state=42))
    ]),
    "SMOTE": ImbPipeline([
        ('preproc', preprocessor),
        ('smote', SMOTE(random_state=42)),
        ('clf', DecisionTreeClassifier(random_state=42))
    ]),
    "UnderSampling": ImbPipeline([
        ('preproc', preprocessor),
        ('under', RandomUnderSampler(random_state=42)),
        ('clf', DecisionTreeClassifier(random_state=42))
    ]),
    "Pond√©ration": ImbPipeline([
        ('preproc', preprocessor),
        ('clf', DecisionTreeClassifier(random_state=42, class_weight='balanced'))  # Pond√©ration des classes
    ])
}

# ----------------------------
# 5. Boucle d‚Äôentra√Ænement et √©valuation
# ----------------------------
resultats = []

for methode, pipeline in pipelines.items():
    print(f"\nüîç M√©thode : {methode}")

    if "SMOTE" in methode:
        tuned_parameters = param_grid_smote
    elif "UnderSampling" in methode:
        tuned_parameters = param_grid_under
    else:
        tuned_parameters = param_grid
    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)    
    grid = GridSearchCV(pipeline, tuned_parameters, cv=cv, scoring='f1', n_jobs=-1, error_score='raise')
    grid.fit(X_train, y_train)

    best_model = grid.best_estimator_
    y_pred = best_model.predict(X_val)
    y_proba = best_model.predict_proba(X_val)[:, 1]  # Probabilit√©s pour la classe 1

    resultats.append({
        'M√©thode': methode,
        'Accuracy': accuracy_score(y_val, y_pred),
        'Pr√©cision': precision_score(y_val, y_pred, zero_division=0),
        'Rappel': recall_score(y_val, y_pred),
        'F1-score': f1_score(y_val, y_pred),
        'ROC AUC': roc_auc_score(y_val, y_proba),
        'Best Params': grid.best_params_
    })

# ----------------------------
# 6. R√©sum√©
# ----------------------------
df_resultats = pd.DataFrame(resultats)
df_resultats = df_resultats.sort_values(by='F1-score', ascending=False).reset_index(drop=True)

print("\nüìä R√©sum√© des performances :")
print(df_resultats)







# Meilleurs hyperparam√®tres obtenus pour l'Arbre de D√©cision
best_params = df_resultats[df_resultats['M√©thode'] == 'Original']['Best Params'].values[0]
print("Meilleurs hyperparam√®tres : ", best_params)

# Reconstruire le pipeline final avec Arbre de D√©cision et original
best_pipeline_tree = ImbPipeline([
    ('preproc', preprocessor), 
    ('clf', DecisionTreeClassifier(
        criterion=best_params['clf__criterion'],  # Crit√®re pour l'arbre
        max_depth=best_params['clf__max_depth'],  # Profondeur maximale
        max_features=best_params['clf__max_features'],  # Nombre de caract√©ristiques √† consid√©rer pour chaque scission
        min_samples_leaf=best_params['clf__min_samples_leaf'],  # Nombre minimal d'√©chantillons par feuille
        min_samples_split=best_params['clf__min_samples_split'],  # Nombre minimal d'√©chantillons pour scinder un noeud
        random_state=best_params['clf__random_state']  # Fixer la graine pour la reproductibilit√©
    ))
])

# Entra√Æner le pipeline final
best_pipeline_tree.fit(X_train, y_train)




from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# 1. Pr√©dictions sur l'ensemble de test
y_pred = best_pipeline_tree.predict(X_val)

# 2. Matrice de confusion normalis√©e par ligne (pourcentage par classe r√©elle)
conf_matrix_normalized = confusion_matrix(y_val, y_pred, normalize='true') * 100  # en %

# 3. Affichage de la matrice de confusion normalis√©e en pourcentage
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix_normalized, annot=True, fmt='.3f', cmap='Blues',
            xticklabels=['Classe 0', 'Classe 1'],
            yticklabels=['Classe 0', 'Classe 1'])
plt.title('Matrice de Confusion Normalis√©e (par ligne, en %)')
plt.xlabel('Pr√©diction')
plt.ylabel('V√©rit√© terrain')
plt.show()

# 4. Affichage du rapport de classification
print("Rapport de classification :\n", classification_report(y_val, y_pred))



import dill

# Enregistrer le meilleur mod√®le avec dill
with open('best_Tree.dill', 'wb') as f:
    dill.dump(best_pipeline_tree, f)
    
# Charger le mod√®le avec dill
with open('best_Tree.dill', 'rb') as f:
    loaded_model = dill.load(f)
# Effectuer une pr√©diction pour tester le mod√®le charg√©
y_pred = loaded_model.predict(X_val)
print(y_pred)













from sklearn.ensemble import RandomForestClassifier
# ----------------------------
# 0. Baseline (mod√®le par d√©faut)
# ----------------------------
print("üìå Baseline : RandomForest sans tuning ni sampling")

baseline_pipeline = ImbPipeline([
    ('preproc', preprocessor),
    ('clf', RandomForestClassifier(random_state=42))
])

baseline_pipeline.fit(X_train, y_train)
y_pred_baseline = baseline_pipeline.predict(X_val)
y_proba_baseline = baseline_pipeline.predict_proba(X_val)[:, 1]

print("‚û°Ô∏è Performance du mod√®le baseline :")
print(f"Accuracy  : {accuracy_score(y_val, y_pred_baseline):.4f}")
print(f"Pr√©cision : {precision_score(y_val, y_pred_baseline, zero_division=0):.4f}")
print(f"Rappel    : {recall_score(y_val, y_pred_baseline):.4f}")
print(f"F1-score  : {f1_score(y_val, y_pred_baseline):.4f}")
print(f"ROC AUC   : {roc_auc_score(y_val, y_proba_baseline):.4f}")

print("\nüìã Hyperparam√®tres par d√©faut du RandomForest :")
for param, val in baseline_pipeline.named_steps['clf'].get_params().items():
    print(f"{param}: {val}")






from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from imblearn.pipeline import Pipeline as ImbPipeline
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import pandas as pd

# ----------------------------
# 1. S√©paration des variables
# ----------------------------
X = df.drop('FraudResult', axis=1)
y = df['FraudResult']

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)

# ----------------------------
# 2. Pr√©traitement dans un transformer unique
# ----------------------------
preprocessor = ColumnTransformer(transformers=[
    ('num', StandardScaler(), numeric_columns),
    ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_columns)
])

# ----------------------------
# 3. Param√®tres de recherche pour RandomForest
# ----------------------------
param_grid = {
    'clf__n_estimators': [200, 300],  # Nombre d'arbres
    'clf__max_depth': [10, 20],  # Profondeur maximale
    'clf__min_samples_split': [5, 10],  # Nombre minimal d'√©chantillons pour diviser un noeud
    'clf__min_samples_leaf': [2, 4],  # Nombre minimal d'√©chantillons dans une feuille
    'clf__max_features': [None],  # Nombre maximal de caract√©ristiques
    'clf__random_state': [42]  # Fixation de l'al√©a pour reproductibilit√©
}

# Param√®tres avec sur√©chantillonnage SMOTE
param_grid_smote = param_grid.copy()
param_grid_smote.update({
    'smote__sampling_strategy': [0.25, 0.5]
})

# Param√®tres avec sous-√©chantillonnage
param_grid_under = param_grid.copy()
param_grid_under.update({
    'under__sampling_strategy': [0.25, 0.5]
})


# ----------------------------
# 4. D√©finition des pipelines imbriqu√©s pour RandomForest
# ----------------------------
pipelines = {
    "RandomForest_Original": ImbPipeline([
        ('preproc', preprocessor),
        ('clf', RandomForestClassifier(random_state=42))
    ]),
    "RandomForest_SMOTE": ImbPipeline([
        ('preproc', preprocessor),
        ('smote', SMOTE(random_state=42)),
        ('clf', RandomForestClassifier(random_state=42))
    ]),
    "RandomForest_UnderSampling": ImbPipeline([
        ('preproc', preprocessor),
        ('under', RandomUnderSampler(random_state=42)),
        ('clf', RandomForestClassifier(random_state=42))
    ]),
    "Pond√©ration": ImbPipeline([
        ('preproc', preprocessor),
        ('clf', RandomForestClassifier(random_state=42, class_weight='balanced'))  # Pond√©ration des classes
   ])     
}

# ----------------------------
# 5. Boucle d‚Äôentra√Ænement et √©valuation pour RandomForest
# ----------------------------
resultats = []

for methode, pipeline in pipelines.items():
    print(f"\nüîç M√©thode : {methode}")

    if "SMOTE" in methode:
        tuned_parameters = param_grid_smote
    elif "UnderSampling" in methode:
        tuned_parameters = param_grid_under
    else:
        tuned_parameters = param_grid
    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)    
    grid = GridSearchCV(pipeline, tuned_parameters, cv=cv, scoring='f1', n_jobs=-1, error_score='raise')
    grid.fit(X_train, y_train)

    best_model = grid.best_estimator_
    y_pred = best_model.predict(X_val)
    y_proba = best_model.predict_proba(X_val)[:, 1]  # Probabilit√©s pour la classe 1

    resultats.append({
        'M√©thode': methode,
        'Accuracy': accuracy_score(y_val, y_pred),
        'Pr√©cision': precision_score(y_val, y_pred, zero_division=0),
        'Rappel': recall_score(y_val, y_pred),
        'F1-score': f1_score(y_val, y_pred),
        'ROC AUC': roc_auc_score(y_val, y_proba),
        'Best Params': grid.best_params_
    })

# ----------------------------
# 6. R√©sum√© des r√©sultats pour RandomForest
# ----------------------------
df_resultats = pd.DataFrame(resultats)
df_resultats = df_resultats.sort_values(by='F1-score', ascending=False).reset_index(drop=True)

print("\nüìä R√©sum√© des performances pour RandomForest :")
print(df_resultats)







# Meilleurs hyperparam√®tres obtenus pour l'Arbre de D√©cision
best_params = df_resultats[df_resultats['M√©thode'] == 'RandomForest_Original']['Best Params'].values[0]
print("Meilleurs hyperparam√®tres : ", best_params)

# Reconstruire le pipeline final avec Arbre de D√©cision et original
best_pipeline_RandomForest = ImbPipeline([
    ('preproc', preprocessor), 
    ('clf', RandomForestClassifier(
        n_estimators=best_params['clf__n_estimators'], 
        max_depth=best_params['clf__max_depth'], 
        max_features=best_params['clf__max_features'],  
        min_samples_leaf=best_params['clf__min_samples_leaf'], 
        min_samples_split=best_params['clf__min_samples_split'], 
        random_state=best_params['clf__random_state'] 
    ))
])

# Entra√Æner le pipeline final
best_pipeline_RandomForest.fit(X_train, y_train)




from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# 1. Pr√©dictions sur l'ensemble de test
y_pred = best_pipeline_RandomForest.predict(X_val)

# 2. Matrice de confusion normalis√©e par ligne (pourcentage par classe r√©elle)
conf_matrix_normalized = confusion_matrix(y_val, y_pred, normalize='true') * 100  # en %

# 3. Affichage de la matrice de confusion normalis√©e en pourcentage
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix_normalized, annot=True, fmt='.3f', cmap='Blues',
            xticklabels=['Classe 0', 'Classe 1'],
            yticklabels=['Classe 0', 'Classe 1'])
plt.title('Matrice de Confusion Normalis√©e (par ligne, en %)')
plt.xlabel('Pr√©diction')
plt.ylabel('V√©rit√© terrain')
plt.show()

# 4. Affichage du rapport de classification
print("Rapport de classification :\n", classification_report(y_val, y_pred))



import dill

# Enregistrer le meilleur mod√®le avec dill
with open('best_RandomForest.dill', 'wb') as f:
    dill.dump(best_pipeline_RandomForest, f)
    
# Charger le mod√®le avec dill
with open('best_RandomForest.dill', 'rb') as f:
    loaded_model = dill.load(f)
# Effectuer une pr√©diction pour tester le mod√®le charg√©
y_pred = loaded_model.predict(X_val)
print(y_pred)









from lightgbm import LGBMClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from imblearn.pipeline import Pipeline as ImbPipeline
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import pandas as pd

# ----------------------------
# 1. S√©paration des variables
# ----------------------------
X = df.drop('FraudResult', axis=1)
y = df['FraudResult']

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)

# ----------------------------
# 2. Pr√©traitement
# ----------------------------
preprocessor = ColumnTransformer(transformers=[
    ('num', StandardScaler(), numeric_columns),
    ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_columns)
])

# ----------------------------
# 0. Baseline (mod√®le par d√©faut)
# ----------------------------
print("üìå Baseline : LightGBM sans tuning ni sampling")

baseline_pipeline = ImbPipeline([
    ('preproc', preprocessor),
    ('clf', LGBMClassifier(random_state=42))
])

baseline_pipeline.fit(X_train, y_train)
y_pred_baseline = baseline_pipeline.predict(X_val)
y_proba_baseline = baseline_pipeline.predict_proba(X_val)[:, 1]

print("‚û°Ô∏è Performance du mod√®le baseline :")
print(f"Accuracy  : {accuracy_score(y_val, y_pred_baseline):.4f}")
print(f"Pr√©cision : {precision_score(y_val, y_pred_baseline, zero_division=0):.4f}")
print(f"Rappel    : {recall_score(y_val, y_pred_baseline):.4f}")
print(f"F1-score  : {f1_score(y_val, y_pred_baseline):.4f}")
print(f"ROC AUC   : {roc_auc_score(y_val, y_proba_baseline):.4f}")

# ----------------------------
# Affichage des hyperparam√®tres par d√©faut
# ----------------------------
print("\nüìã Hyperparam√®tres par d√©faut de LightGBM :")
for param, val in baseline_pipeline.named_steps['clf'].get_params().items():
    print(f"{param}: {val}")






from lightgbm import LGBMClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from imblearn.pipeline import Pipeline as ImbPipeline
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import pandas as pd

# ----------------------------
# 1. S√©paration des variables
# ----------------------------
X = df.drop('FraudResult', axis=1)
y = df['FraudResult']

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)

# ----------------------------
# 2. Pr√©traitement dans un transformer unique
# ----------------------------
preprocessor = ColumnTransformer(transformers=[
    ('num', StandardScaler(), numeric_columns),
    ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_columns)
])

# ----------------------------
# 3. Param√®tres de recherche pour LGBM
# ----------------------------
param_grid = {
    'clf__n_estimators': [200, 300],
    'clf__max_depth': [10, 20],
    'clf__learning_rate': [0.05, 0.2],
    'clf__num_leaves': [20, 40],
    'clf__random_state': [42]
}

# Param√®tres avec SMOTE
param_grid_smote = param_grid.copy()
param_grid_smote.update({
    'smote__sampling_strategy': [0.25, 0.5]
})

# Param√®tres avec sous-√©chantillonnage
param_grid_under = param_grid.copy()
param_grid_under.update({
    'under__sampling_strategy': [0.25, 0.5]
})

# ----------------------------
# 4. D√©finition des pipelines pour LGBM
# ----------------------------
pipelines = {
    "LightGBM_Original": ImbPipeline([
        ('preproc', preprocessor),
        ('clf', LGBMClassifier(random_state=42))
    ]),
    "LightGBM_SMOTE": ImbPipeline([
        ('preproc', preprocessor),
        ('smote', SMOTE(random_state=42)),
        ('clf', LGBMClassifier(random_state=42))
    ]),
    "LightGBM_UnderSampling": ImbPipeline([
        ('preproc', preprocessor),
        ('under', RandomUnderSampler(random_state=42)),
        ('clf', LGBMClassifier(random_state=42))
    ]),
    "Pond√©ration": ImbPipeline([
        ('preproc', preprocessor),
        ('clf', LGBMClassifier(random_state=42, class_weight='balanced'))
    ])
}

# ----------------------------
# 5. Boucle d‚Äôentra√Ænement et √©valuation pour LGBM
# ----------------------------
resultats = []

for methode, pipeline in pipelines.items():
    print(f"\nüîç M√©thode : {methode}")

    if "SMOTE" in methode:
        tuned_parameters = param_grid_smote
    elif "UnderSampling" in methode:
        tuned_parameters = param_grid_under
    else:
        tuned_parameters = param_grid
    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)    
    grid = GridSearchCV(pipeline, tuned_parameters, cv=cv, scoring='f1', n_jobs=-1, error_score='raise')
    grid.fit(X_train, y_train)

    best_model = grid.best_estimator_
    y_pred = best_model.predict(X_val)
    y_proba = best_model.predict_proba(X_val)[:, 1]

    resultats.append({
        'M√©thode': methode,
        'Accuracy': accuracy_score(y_val, y_pred),
        'Pr√©cision': precision_score(y_val, y_pred, zero_division=0),
        'Rappel': recall_score(y_val, y_pred),
        'F1-score': f1_score(y_val, y_pred),
        'ROC AUC': roc_auc_score(y_val, y_proba),
        'Best Params': grid.best_params_
    })

# ----------------------------
# 6. R√©sum√© des r√©sultats pour LGBM
# ----------------------------
df_resultats = pd.DataFrame(resultats)
df_resultats = df_resultats.sort_values(by='F1-score', ascending=False).reset_index(drop=True)

print("\nüìä R√©sum√© des performances pour LightGBM :")
print(df_resultats)






import lightgbm as lgb
from imblearn.pipeline import Pipeline as ImbPipeline  # Assure-toi d'importer la bonne classe Pipeline

# Meilleurs hyperparam√®tres obtenus pour LightGBM
best_params = df_resultats[df_resultats['M√©thode'] == 'LightGBM_SMOTE']['Best Params'].values[0]
print("Meilleurs hyperparam√®tres : ", best_params)

# Reconstruire le pipeline final avec LightGBM
best_pipeline_LightGBM = ImbPipeline([
    ('preproc', preprocessor),  
    ('smote', SMOTE(sampling_strategy=best_params['smote__sampling_strategy'])),  # Application de SMOTE
    ('clf', lgb.LGBMClassifier(
        learning_rate=best_params['clf__learning_rate'],  # Taux d'apprentissage
        max_depth=best_params['clf__max_depth'],          # Profondeur maximale des arbres
        n_estimators=best_params['clf__n_estimators'],    # Nombre d'arbres
        num_leaves=best_params['clf__num_leaves'],        # Nombre de feuilles par arbre
        random_state=best_params['clf__random_state']     # Pour la reproductibilit√©
    ))
])

# Entra√Æner le pipeline final
best_pipeline_LightGBM.fit(X_train, y_train)




from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# 1. Pr√©dictions sur l'ensemble de test
y_pred = best_pipeline_LightGBM.predict(X_val)

# 2. Matrice de confusion normalis√©e par ligne (pourcentage par classe r√©elle)
conf_matrix_normalized = confusion_matrix(y_val, y_pred, normalize='true') * 100  # en %

# 3. Affichage de la matrice de confusion normalis√©e en pourcentage
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix_normalized, annot=True, fmt='.3f', cmap='Blues',
            xticklabels=['Classe 0', 'Classe 1'],
            yticklabels=['Classe 0', 'Classe 1'])
plt.title('Matrice de Confusion Normalis√©e (par ligne, en %)')
plt.xlabel('Pr√©diction')
plt.ylabel('V√©rit√© terrain')
plt.show()

# 4. Affichage du rapport de classification
print("Rapport de classification :\n", classification_report(y_val, y_pred))


import dill

# Enregistrer le meilleur mod√®le avec dill
with open('best_SMOTE_LightGBM.dill', 'wb') as f:
    dill.dump(best_pipeline_LightGBM, f)
    
# Charger le mod√®le avec dill
with open('best_SMOTE_LightGBM.dill', 'rb') as f:
    loaded_model = dill.load(f)
# Effectuer une pr√©diction pour tester le mod√®le charg√©
y_pred = loaded_model.predict(X_val)
print(y_pred)

